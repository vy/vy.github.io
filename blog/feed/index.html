<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://vlkan.com//</id>
  <title>Volkan Yazıcı's Soap Co.</title>
  <updated>2018-11-14T07:54:00Z</updated>
  <link rel="alternate" href="https://vlkan.com//"/>
  <link rel="self" href="https://vlkan.com//blog/feed/"/>
  <author>
    <name>Volkan Yazıcı</name>
    <uri>https://vlkan.com/</uri>
  </author>
  <entry>
    <id>tag:vlkan.com,2018-11-14://blog/post/2018/11/14/elasticsearch-primary-data-store/</id>
    <title type="html">Using Elasticsearch as the Primary Data Store</title>
    <published>2018-11-14T07:54:00Z</published>
    <updated>2018-11-14T07:54:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2018/11/14/elasticsearch-primary-data-store/"/>
    <content type="html">
&lt;p&gt;The biggest e-commerce company in the Netherlands and Belgium,
&lt;a href="https://bol.com"&gt;bol.com&lt;/a&gt;, set out on a 4 year journey to rethink and rebuild
their entire &lt;a href="https://en.wikipedia.org/wiki/Extract,_transform,_load"&gt;ETL (Extract, Transform, Load)&lt;/a&gt;
pipeline, that has been cooking up the data used by its search engine since
the dawn of time. This more than a decade old white-bearded giant, breathing
in the dungeons of shady Oracle PL/SQL hacks, was in a state of decay, causing
ever increasing hiccups on production. A rewrite was inevitable. After
drafting many blueprints, we went for a Java service backed by &lt;strong&gt;Elasticsearch
as the primary storage!&lt;/strong&gt; This idea brought shivers to even the most senior
Elasticsearch consultants hired, so to ease your mind I’ll walk you through
why we took such a radical approach and how we managed to escape our legacy.&lt;/p&gt;

&lt;p&gt;Before diving into the details, let me share a 2,000ft overview of an
e-commerce search setup that will help you to gain a better understanding of
the subjects discussed onwards. Note that this simplification totally omits a
nebula of incorporated caching layers, systems orchestrating multiple search
clusters, queues with custom flush and replay functionalities, in-place
resiliency mechanisms, services maintaining deprecated search entities to
avoid getting ranked down by bots due to 404s, circuit breakers, throttlers,
load balancers, etc. But it is still accurate enough to convey the general
idea.&lt;/p&gt;

&lt;p&gt;&lt;img src="overview.jpg" alt="Architecture Overview"&gt;&lt;/p&gt;

&lt;h1 id="table-of-contents"&gt;Table of Contents&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
&lt;a href="#search"&gt;The Search&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href="#what-is-search"&gt;What is search anyway?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href="#who-is-using-search"&gt;Who/What is using search?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href="#what-about-performance"&gt;What about performance?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href="#how-volatile"&gt;How volatile is the content?&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
&lt;a href="#etl"&gt;The ETL&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href="#content-stream"&gt;Real-time Content Stream&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href="#configuration-stream"&gt;Configuration Stream&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
&lt;a href="#operational-overview"&gt;Operational Overview&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href="#configuration-mutations"&gt;Configuration Mutations&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href="#configuration-predicates"&gt;Configuration Predicates&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href="#old-etl"&gt;The Old ETL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
&lt;a href="#battle-of-storage-engines"&gt;The Battle of Storage Engines&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href="#benchmark-setup"&gt;Benchmark Setup&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href="#benchmark-results"&gt;Benchmark Results&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
&lt;a href="#new-etl"&gt;The New ETL&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href="#primary-storage-elasticsearch"&gt;The Primary Storage: Elasticsearch&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href="#configuration-dsl-json-groovy"&gt;The Configuration DSL: JSON and Groovy&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="#acknowledgements"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name="search"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id="the-search"&gt;The Search&lt;/h1&gt;

&lt;p&gt;&lt;i&gt;[Before going any further, I want to take this opportunity to align you on
what exactly I do mean by &lt;em&gt;search&lt;/em&gt;. I hope this will help you to better wrap
your mind around the ultimate consumer of ETL. That being said, feel free to
skip this section and directly jump to the ETL deep dive in the next
section.]&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;Many people tend to make the mistake of having a narrow view on search at
e-commerce and confining its use case to a mere term scavenging in a
mountainous stack of product attributes. While this statement holds to a
certain extent, it resembles a cherry located at the tip of an iceberg. (In
&lt;a href="/blog/post/2018/02/17/varnishing-search-performance/"&gt;Varnishing Search Performance&lt;/a&gt;
presentation, I tried to summarize how difficult it can get just to add a
caching layer between your search logic and backend.) There are books written,
university lectures offered, and computer science branches dedicated on the
matter. But let me try to briefly elaborate this from an engineering
standpoint.&lt;/p&gt;

&lt;p&gt;&lt;a name="what-is-search"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="what-is-search-anyway"&gt;What is search anyway?&lt;/h2&gt;

&lt;p&gt;If I would try to give a general, but far from complete, overview, it enables
one to&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;search for a term in hundreds of product attributes, where &lt;em&gt;matching&lt;/em&gt;
and &lt;em&gt;ranking&lt;/em&gt; are curated with directly or indirectly available consumer
(are you a PS4 owner searching for the newest “Call of Duty”?) and
relevance (you probably meant a band by typing “The Doors”, which is
irrelevant for “Doors &amp;amp; Windows” department) contexts,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;browse (basically a search without a term) in thousands of categories
with similar ranking mechanics used in search aforementioned,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;beam up directly to a certain product or category given the input matches
with certain patterns (EAN, ISBN, ISSN, etc.) or merchandising rules (any
syntactic and/or semantic combination of “wine glasses” should end the
flow in a particular department, etc.),&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;implicitly trigger multiple searches under the hood (e.g. narrowing
down to a lower category or widening up to a higher category, etc.)
to enhance the results,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;and decorate every listing with faceting (you probably want to see
“Capacity” facet rather than “Shoe Size” while searching/browsing in
“Harddisks”) support.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name="who-is-using-search"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="whowhat-is-using-search"&gt;Who/What is using search?&lt;/h2&gt;

&lt;p&gt;This is a big debate. But I know a handful of certain consumers:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Customers:&lt;/strong&gt; People who search and buy goods. They look harmless, until
one gets exposed to them on a &lt;a href="https://en.wikipedia.org/wiki/Black_Friday_%28shopping%29"&gt;Black Friday&lt;/a&gt;
where they work hand to hand in masses to &lt;a href="https://en.wikipedia.org/wiki/Denial-of-service_attack"&gt;DDoS&lt;/a&gt;
the entire infrastructure.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Bots:&lt;/strong&gt; They periodically (a couple of times a day at most, as of the
date of this writing) try to digest your entire catalog into their system
for two main purposes:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Integrate the catalog into their own search engine (that is, Google),&lt;/li&gt;
      &lt;li&gt;Tune their pricing strategy (that is, competitors)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;The worst part of handling bot traffic is you cannot always throttle them
(for instance, Google takes into account website latencies for rankings) and
you need to make sure they do not harm the customer traffic. Food for
thought: Imagine your customers swarming at your shop at Christmas Eve
and Google decided to spider your entire catalog with thousands of requests
per second.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Partners:&lt;/strong&gt; Your business partners can also scan your catalog
periodically to integrate into their own systems. (Fun fact: Some even
require a daily Excel export.) One can classify them as bots only
interested in a subset of the data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Internal services:&lt;/strong&gt; Last time I counted, there were 20+ internal
services using search to enhance their results in addition to the
users I listed above. Their usage can constitute up to 50% of the
traffic.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the case of partners and internal services, one might argue why do they
need the search data rather than directly accessing the raw product attributes
and offers. The answer is simple: They also use additional attributes (e.g.,
facets, categories) incorporated at the ETL pipeline. Hence, rather than
exposing the internal ETL system to them, it is more convenient to manage them
at the search gateway which is known to have battle-tested scalability and
resiliency measures.&lt;/p&gt;

&lt;p&gt;&lt;a name="what-about-performance"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="what-about-performance"&gt;What about performance?&lt;/h2&gt;

&lt;p&gt;As decades-long experience in this domain points, making search 10ms faster
can yield millions of euros extra revenue depending on the scale of your
business. Unfortunately, this equation works the other way around as well.
Hence, you are always expected to perform under a certain latency and above a
certain throughput threshold.&lt;/p&gt;

&lt;p&gt;&lt;a name="how-volatile"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="how-volatile-is-the-content"&gt;How volatile is the content?&lt;/h2&gt;

&lt;p&gt;Very, very, very volatile! I cannot emphasize this enough and I believe this
is a crucial difference that puts e-commerce search apart from Google-like
search engines – recall the conflict between Google and Twitter for indexing
tweets. Maybe examples can help to convey the idea better:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A product might have multiple offers (bol.com offer, partner offer, etc.)
featuring varying properties (pricing, deliverability, discounts, etc.)
where both offers and/or their properties are highly volatile. The offer
might run out of stock, the price might change, etc. While customer-facing
web pages are enhanced with the most recent data at runtime, search index
might lag behind and provide an eventually consistent view. The volatility
in this context might range from seconds to months. On prime time, e.g. on
Valentine’s Day, you don’t want your search engine to return gift listings
that ran out of stock a couple of seconds ago.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Your manual (triggered by shop specialists) and automated (artificial
intelligence, machine learning driven) processes can alter the category
tree, add new facets, tune the exposure of existing facets, modify the
search behavior (e.g., flows triggered by merchandising rules), add context
sensitive (e.g. category-dependent) thesaurus entries, synonyms, introduce
new rankings, etc. These changes might necessitate the update of millions of
documents retroactively.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This &lt;em&gt;volatility&lt;/em&gt; debate will take a prominent role while deciding on the
architecture of the next ETL pipeline, which I will elaborate in a minute.&lt;/p&gt;

&lt;p&gt;&lt;a name="etl"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id="the-etl"&gt;The ETL&lt;/h1&gt;

&lt;p&gt;In the domain of search at e-commerce,
&lt;a href="https://en.wikipedia.org/wiki/Extract,_transform,_load"&gt;ETL&lt;/a&gt; denotes the
pipeline where the input is a multitude of information sources (product
attributes, offers, discounts, rankings, facets, synonyms, thesaurus entries,
etc.) and the output is the
&lt;a href="https://en.wikipedia.org/wiki/Denormalization"&gt;denormalized&lt;/a&gt; input
constituting search-ready documents optimized for search query performance.
Wait a second? If an ETL pipeline just delivers some optimization purposes,
doesn’t this sound like that one can have a search without it? Sorta… That
is indeed possible to a certain extent. If we would put the details aside for
a moment, we can roughly compare the two approaches as follows:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Strategy&lt;/th&gt;
      &lt;th&gt;Advantages&lt;/th&gt;
      &lt;th&gt;Disadvantages&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Without ETL&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;
        Every change in the input sources take immediate effect. (Hence, almost
        zero index time cost.)
      &lt;/td&gt;
      &lt;td&gt;
        Latency and throughput hurts dramatically due to necessitated join and
        enrich operations on input sources at query time.
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;With ETL&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;
        Since all potential data to satisfy search requests has already
        been baked into the index, search necessitates the least amount of
        effort to satisfy a request at query time.
      &lt;/td&gt;
      &lt;td&gt;
        Every change in the input sources will necessitate pre-processing
        affecting a multitude of products ranging from a couple to millions.
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Put another way, ETL is all about the trade-off between index- versus
query-time performance. In the light of all these and given&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;our existing ETL was functionally comprehensive enough,&lt;/li&gt;
  &lt;li&gt;query time performance of Elasticsearch has already been suffering due to
faceting, internally triggered queries, etc. to an extent external caching
becomes a necessity,&lt;/li&gt;
  &lt;li&gt;and search latency has a big impact on the revenue,&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;we took the thick ETL pipeline path.&lt;/p&gt;

&lt;p&gt;But what is this ETL pipeline really? What does it literally do? In order to
answer these questions, let me focus your attention to the input sources going
into the ETL pipeline:&lt;/p&gt;

&lt;p&gt;&lt;img src="etl.jpg" alt="ETL Input Sources"&gt;&lt;/p&gt;

&lt;p&gt;&lt;i&gt;[GPC stands for &lt;a href="https://www.gs1.org/standards/gpc"&gt;Global Product Classification&lt;/a&gt;,
which is de facto commercial categorization of goods varying from a car to
a litre of milk.]&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;These two input sources, content and configuration, feature two totally
different execution patterns framing the functional requirements of the
potential ETL solutions, hence, play the uttermost critical role in justifying
the plan we picked. Let’s examine them further:&lt;/p&gt;

&lt;p&gt;&lt;a name="content-stream"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="real-time-content-stream"&gt;Real-time Content Stream&lt;/h2&gt;

&lt;p&gt;Here the ETL pipeline listens from more than a dozen queues for updates
ranging from product attributes to offers, offer-specific discounts to
rankings, etc. all formatted in &lt;a href="https://json.org/"&gt;JSON&lt;/a&gt;. Fortunately, each
real-time content stream message triggers a single product update. Let me
exemplify this with a case: when &lt;code&gt;disk_capacity_bytes&lt;/code&gt; attribute of a product
changes, we&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;first fetch the relevant document from the storage,&lt;/li&gt;
  &lt;li&gt;update its &lt;code&gt;disk_capacity_bytes&lt;/code&gt; attribute,&lt;/li&gt;
  &lt;li&gt;apply configuration(s) matching with the last state of the updated document,&lt;/li&gt;
  &lt;li&gt;and persist the obtained result back.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are some concerns need to be addressed here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;This is a pretty &lt;em&gt;CPU intensive&lt;/em&gt; operation. Configurations, in essence, are
rules in the form of &lt;code&gt;(predicate, mutation)&lt;/code&gt; pairs defined via
business-friendly screens by shop specialists. When an attribute of a
document gets updated, this change might be of interest to many
configurations which are determined by performing an inverse lookup on tens
of thousands of configuration predicates (e.g., &lt;code&gt;attrs.disk_capacity_bytes !=
null&lt;/code&gt;) matching with the last state of the document. Later on mutations
(e.g., &lt;code&gt;doc.disk_capacity_gigabytes = attrs.disk_capacity_bytes / 1e9&lt;/code&gt;) of
the found configurations are executed to let them shape the document
according to their needs.&lt;/p&gt;

    &lt;p&gt;This innocent looking procedure sneakily introduces two critical issues
under the hood:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;em&gt;How would you represent the configuration predicate such that you can
match them against the content?&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;How would you represent the configuration mutation such that you can
execute them against the content?&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;And it goes without saying, both concerns aforementioned need to be
engineered efficiently. You are expected to repeat this procedure on each
message JSON of the real-time content stream where the traffic is in the
order of millions per day.&lt;/p&gt;

    &lt;p&gt;As a concrete configuration example consider the following: You have two
“Disk Capacity” facets defined by business: one for computers, one for
smart phones departments. The first one translates the
&lt;code&gt;disk_capacity_bytes&lt;/code&gt; into a &lt;code&gt;disk_capacity_terabytes&lt;/code&gt; attribute which is
defined to be exposed when &lt;code&gt;category == "computers"&lt;/code&gt; and the second
translates into a &lt;code&gt;disk_capacity_gigabytes&lt;/code&gt; attribute which is defined to
be exposed when &lt;code&gt;category == "smart phones"&lt;/code&gt;. Here both configurations are
executed when the &lt;code&gt;attrs.disk_capacity_bytes != null&lt;/code&gt; predicate holds.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This operation needs to be performed &lt;em&gt;atomically&lt;/em&gt;. Two concurrent operations
touching to the same product should not result in a corrupt content.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name="configuration-stream"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="configuration-stream"&gt;Configuration Stream&lt;/h2&gt;

&lt;p&gt;Configurations are the rules defined via business-friendly screens. There
modifications done by shop specialists are published in snapshots when they
think the changes grow into a stable state that they are ready to be exposed
to the customer. Each published configuration snapshot ends up serving three
purposes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;search gateway uses it to determine how to query the search index,&lt;/li&gt;
  &lt;li&gt;ETL pipeline uses it to process the real-time content stream,&lt;/li&gt;
  &lt;li&gt;and ETL pipeline &lt;em&gt;retroactively updates&lt;/em&gt; the documents that are potentially
affected.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;While the first two are relatively cheap operations, the last one is the
elephant in the room! This is the first time in our beautiful tale described
so far that we need to propagate a change to millions of documents. Let me
further explain this in an example:&lt;/p&gt;

&lt;p&gt;Let’s consider that the following category definition:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-javascript"&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gpc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;family_id&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1234&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gpc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;chunk_id&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;5678&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;category&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"books"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;is modified as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-javascript"&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gpc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;family_id&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1234&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gpc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;chunk_id&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mh"&gt;0xDEADBEEF&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;category&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"AWESOME BOOKS"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sir, you are in trouble! As the very ETL pipeline, what you are expected to
deliver is to&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;find products that are matching with the old predicate,&lt;/li&gt;
  &lt;li&gt;revert the changes of the old configuration mutation by removing &lt;code&gt;books&lt;/code&gt; from the &lt;code&gt;category&lt;/code&gt; field,&lt;/li&gt;
  &lt;li&gt;find products that are matching with the new predicate,&lt;/li&gt;
  &lt;li&gt;and apply the changes of the new configuration mutation by adding &lt;code&gt;AWESOME BOOKS&lt;/code&gt; to the &lt;code&gt;category&lt;/code&gt; field.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This easier said than done operation contains many implicit concerns:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ETL needs to avoid removing &lt;code&gt;books&lt;/code&gt; from the &lt;code&gt;category&lt;/code&gt; field if there are
rules, other than the changed one, adding &lt;code&gt;books&lt;/code&gt; to the very same &lt;code&gt;category&lt;/code&gt;
field. There are two ways you can approach to this:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;With every value added to a field, store a meta information pointing
to the rules associated with that value. These back-tracking pointers
optimize the check whether a value can be removed or not, with the cost
of maintaining them in an ocean of values.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;After removing every value, put the product back into the ETL pipeline
just like handling products in the real-time content stream. If there are
any rules, other than the changed one, adding &lt;code&gt;books&lt;/code&gt; to the very same
&lt;code&gt;category&lt;/code&gt; field, they will kick in. This simple approach comes with the
cost of a CPU intensive and unfortunately mostly redundant processing.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Given that configuration predicates are allowed to access any field, how
would one represent a predicate and translate this into an ETL storage query
filter that performs well? (You would not want to scan the whole data set
for each predicate that is changed, right? Well… depends.)&lt;/p&gt;

    &lt;p&gt;Let’s first discuss the representation of predicates issue, which was also a
concern in the real-time content stream processing. Here you might first
fall into the trap of whitelisting the operators (&lt;code&gt;==&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;,
&lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;~=&lt;/code&gt;) and the content attributes (&lt;code&gt;attrs.gpc.family_id&lt;/code&gt;,
&lt;code&gt;attrs.gpc.chunk_id&lt;/code&gt;, &lt;code&gt;attrs.disk_capacity_bytes&lt;/code&gt;, etc.) that are allowed in
configuration predicates. While whitelisting operators is fine, whitelisting
the content attributes implies that the ETL pipeline, the configuration
administration GUIs, etc. all needs to have the knowledge of this whitelist
which strictly depends on the structure of the real-time content stream
message structures. Whenever the message structures change or you want to
add a new attribute to this whitelist, both happen a couple of times every
year, you need to propagate this to many components in your service milky
way and perform a deploy without downtime.&lt;/p&gt;

    &lt;p&gt;What about translating these predicate representations into efficient ETL
storage query filters? Let’s take the simplest approach: Represent each
attribute with a separate field. Then let me ask you the following
questions:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;If you would opt for using an RDBMS, you can represent attributes by
columns and create an index for each individual column. (Ouch!) Thanks to
the half-century battle-tested RDBMS literature, the database can easily
optimize and perform an index scan for the constructed queries:&lt;/p&gt;

        &lt;pre&gt;&lt;code class="language-sql"&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt;
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;
 &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;attrs_gpc_family_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'1234'&lt;/span&gt;
   &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;attrs_gpc_chunk_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'5678'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

        &lt;p&gt;That being said… What if you hit to the maximum column count limitation?
(Yes, we did!) Further, what about attributes that are list of objects:&lt;/p&gt;

        &lt;pre&gt;&lt;code class="language-json"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"authors"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;"fname"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Volkan"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;"lname"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Yazici"&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;"fname"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Lourens"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;"lname"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Heijs"&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

        &lt;p&gt;You definitely cannot store these in a single column and still query each
individual component. Ok, then you can normalize the data as follows:&lt;/p&gt;

        &lt;pre&gt;&lt;code class="language-sql"&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt;
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
       &lt;span class="n"&gt;attribute&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;a1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
       &lt;span class="n"&gt;attribute&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;a2&lt;/span&gt;
 &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;a1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;a1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'gpc_family_id'&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;a1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'1234'&lt;/span&gt;
   &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;a2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;a2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'gpc_chunk_id'&lt;/span&gt;  &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;a2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'5678'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

        &lt;p&gt;So far so good. But… In a matter of months, you will need to start
partitioning tables and maybe even move certain partitions into separate
database instances to maintain the latency under a certain threshold.
(Yes, we did this as well!) But this never-ending database structure
optimization more and more feels like you are inventing your own
distributed database using a plain RDBMS. Does this really still need to
be this way in 2018?&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If you would opt for using &lt;a href="https://www.mongodb.com/"&gt;MongoDB&lt;/a&gt;, like using
an RDBMS, you still need create an explicit index on each (whitelisted)
field. For filters involving multiple fields (e.g., &lt;code&gt;attrs.gpc.family_id
== 1234 &amp;amp;&amp;amp; attrs.gpc.chunk_id == 5678&lt;/code&gt;), MongoDB query optimizer can
purpose individual field indices via &lt;a href="https://docs.mongodb.com/manual/core/index-intersection/"&gt;index intersection&lt;/a&gt;.
That being said, our experience with this feature has not been very
pleasant.&lt;/p&gt;

        &lt;p&gt;The issue where attributes might contain list of objects is
&lt;a href="https://docs.mongodb.com/manual/tutorial/query-array-of-documents/"&gt;not a problem for MongoDB&lt;/a&gt;.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If you would opt for &lt;a href="https://cloud.google.com/datastore"&gt;Google Cloud Datastore&lt;/a&gt;,
you will need to create explicit indices for each potential filter
combination and order matters! Yes, you read that right! Let me exemplify
this bizarre situation. If you have configurations with the following
predicates:&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;&lt;code&gt;attrs.gpc.family_id == 1234&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code&gt;attrs.gpc.chunk_id == 5678&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code&gt;attrs.gpc.family_id == 1234 &amp;amp;&amp;amp; attrs.gpc.chunk_id == 5678&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;&lt;code&gt;attrs.gpc.chunk_id == 5678 &amp;amp;&amp;amp; attrs.gpc.family_id == 1234&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;you need to define 4 different indices! Ouch! This in its own was a
Datastore show stopper for us.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If you would opt for &lt;a href="https://www.elastic.co/products/elasticsearch"&gt;Elasticsearch&lt;/a&gt;,
all fields are indexed by default and you can use them in any combination!
Yay! No need for whitelisting! And similar to MongoDB, Elasticsearch also
allows &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html"&gt;querying list of objects&lt;/a&gt;,
you just need to declare them explicitly as &lt;code&gt;nested&lt;/code&gt;. If you don’t even
want to worry about that, you can add a dynamic mapping template to make
each object nested by default. Following is the index mapping you can use
for that purpose:&lt;/p&gt;

        &lt;pre&gt;&lt;code class="language-json"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"date_detection"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;"dynamic_templates"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;"strings"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;"match_mapping_type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"string"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="nt"&gt;"mapping"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"keyword"&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;"objects"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;"match_mapping_type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"object"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="nt"&gt;"mapping"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"nested"&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

        &lt;p&gt;Above mapping also disables analyzing the fields of type &lt;code&gt;string&lt;/code&gt;, since
we are not interested in performing fuzzy queries. Clearly, date detection
is disabled for similar reasons.&lt;/p&gt;

        &lt;p&gt;These being said, Elasticsearch is known to suffer from deteriorating
query performance over time when exposed to high update rates.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name="operational-overview"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id="operational-overview"&gt;Operational Overview&lt;/h1&gt;

&lt;p&gt;So far we examined the current ETL setup with concrete examples for several
cases. We broke down the system into its individual input sources and detailed
their implications on certain architectural decisions. Let’s wrap up this
mind-boggling details into operational abstractions:&lt;/p&gt;

&lt;p&gt;&lt;img src="etl-abstraction.jpg" alt="The ETL: Operational Overview"&gt;&lt;/p&gt;

&lt;p&gt;Given these operational abstractions, let me summarize the constraints the
configuration components (predicate and mutation) imply.&lt;/p&gt;

&lt;p&gt;&lt;a name="configuration-mutations"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="configuration-mutations"&gt;Configuration Mutations&lt;/h2&gt;

&lt;p&gt;If you would recall, configuration mutations were simple document enhancement
instructions that I exemplified as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-javascript"&gt;&lt;span class="nx"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;category&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"books"&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here &lt;code&gt;doc&lt;/code&gt; is a dictionary denoting the ETL’ed document source and mutation
“adds” &lt;code&gt;books&lt;/code&gt; value to its &lt;code&gt;category&lt;/code&gt; field. This (for simplification
purposes, JavaScript-employed) innocent looking expression can (and does!) go
to unintended extents:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-javascript"&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;suitable_for_month&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;childhood_stage&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"newborn"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;suitable_for_month&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;childhood_stage&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"infant"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;suitable_for_month&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;48&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;childhood_stage&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"toddler"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The choice of the mutation &lt;a href="https://en.wikipedia.org/wiki/Domain-specific_language"&gt;DSL&lt;/a&gt;
employed is expected to deliver the following requirements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It “must” support JSON input and output for the real-time content stream.
(See step B4 in the figure.)&lt;/li&gt;
  &lt;li&gt;It “should” support ETL storage input and output for the configuration
snapshot stream. (See step A4 in the figure.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The reason that the latter functionality marked as optional is that the ETL
pipeline can also retrieve these documents in raw from the storage, convert
them to JSON, execute mutations, and persist them back again – assuming data
integrity is provided by other means, e.g., transactions, retries powered by
compare-and-swap operations, etc.&lt;/p&gt;

&lt;p&gt;&lt;a name="configuration-predicates"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="configuration-predicates"&gt;Configuration Predicates&lt;/h2&gt;

&lt;p&gt;Configuration predicates were simple conditions restricted to use a
whitelisted set of operators (&lt;code&gt;==&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;,   &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;~=&lt;/code&gt;)
supporting grouping:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-javascript"&gt;&lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gpc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;family_id&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1234&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nx"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;gpc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;chunk_id&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;5678&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similar to mutations, the choice of the predicate DSL used is expected to
deliver the following requirements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It “must” support JSON input for the real-time content stream. (See step B2
in the figure.)&lt;/li&gt;
  &lt;li&gt;It “should” support ETL storage input for determining the affected documents
by the configuration snapshot delta. (See step A4 in the figure.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We relaxed the latter constraint since one can very well prefer to put the
entire stored document collection (Ouch!) back into the ETL pipeline, process
them, detect the changed ones, and persist the updates. This approach has
certain assumptions though:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We don’t need to perform this too often. That is, the frequency of
configuration snapshots are relatively low, e.g., max. a couple of times a
day.&lt;/li&gt;
  &lt;li&gt;The snapshot deltas affect a significant percentage of the entire collection
to an extent that the advantage of finding and processing only the affected
documents diminishes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given you still need to make a back of the envelope calculation on your cloud
bill for each approach, our years of statistics in the ETL snapshot
configuration point that most of the time snapshot deltas affect at most 5% of
the entire collection and the average is less than 1% – thanks to the
incremental updates carried out by shop specialists. Hence, performing a
complete ETL a couple of times a day feels like overkill and hurts the
engineer within you.&lt;/p&gt;

&lt;p&gt;&lt;a name="old-etl"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id="the-old-etl"&gt;The Old ETL&lt;/h1&gt;

&lt;p&gt;The old ETL was a single Oracle database where the configurations were modeled
in PL/SQL. Since the configuration abstraction language was the very same
language the database uses itself, executing mutations and predicates was
effortless. Hail &lt;a href="https://en.wikipedia.org/wiki/SQL_injection"&gt;SQL injection&lt;/a&gt;
as a feature! Though this came with some notable costs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Using PL/SQL within the abstraction model created both functional and
financial vendor lock-in. The functional deficiency (incompetent
expressiveness, leakage of PL/SQL to irrelevant components) obstructed many
innovations over the years, where it became more and more difficult as time
passed. Additionally, it constituted a significant obstacle for migrating
the service to the cloud. Its financial aspect was negligible at the scale
of &lt;a href="https://bol.com"&gt;bol.com&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Rolling back changes of an updated configuration mutation is quite a
PL/SQL engineering endeavor to implement in practice. This difficulty,
spiced up with the insufficient logging, testing, debugging, profiling, etc.
utilities, drew programmers back from taking this path. &lt;em&gt;Hence, there was a
12+ hours long complete ETL run every night for configuration snapshot
deltas.&lt;/em&gt; This beast tamed by an experienced couple of engineers has a
reputation to have frequent hiccups and make bugs really difficult to debug,
find, and reproduce, let alone fix!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In its previous incarnation, the content attributes were stored in &lt;code&gt;&amp;lt;id,
content_id, key, value&amp;gt;&lt;/code&gt; normalized form. This approach started to suffer from
efficiency aches in the hinges pulling the ETL’ed data to the search index.
Back then hired Oracle consultants examined the usage and recommended to go
with a denormalized structure where each attribute is stored as a column. In
addition to temporarily bandaging up the efficiency related wounds, this
allowed DBAs to let their imaginations go wild to map the attributes to
columns. Recall the attributes composed of objects I mentioned above? Special
characters were used to create such multi-value attributes, which was pretty
much (to put it mildly) unpleasant. But the killer bullet came in the form of
a six-inch punch referred as &lt;a href="https://stackoverflow.com/a/14722914/1278899"&gt;the maximum allowed column count
limit&lt;/a&gt;. But isn’t engineering
all about &lt;a href="https://youtu.be/D_Vg4uyYwEk"&gt;how hard you can get it and keep moving
forward&lt;/a&gt;? Yes, comrade! We thought so and used a
single binary XML column to store attributes, queried them using Oracle XPath
toolbox, escaped attribute values, finally concatenated them into SQL strings
that are eventually executed, and for sure crossed our fingers.&lt;/p&gt;

&lt;p&gt;There are a couple of important details that I could not manage to cover in
the above war diary without spoiling the coherency. Let me drop them here in
no particular order:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Task parallelization is pretty difficult in PL/SQL. We tried patching this
hole via internal Oracle AQs, but I am not really sure whether it improved
or worsened the state.&lt;/li&gt;
  &lt;li&gt;In a database procedure that is expected to run for 12+ hours, Murphy’s law
works flawlessly. Anything that can go wrong, did, does, and will go wrong.
We wisely(!) engineered the system to persist its state at certain check
points constituting retriable handles to invoke when you come in the morning
and see that the ETL crashed.&lt;/li&gt;
  &lt;li&gt;The number of moving components necessitated the use of &lt;a href="https://www.cronacle.com/"&gt;a proprietary
scheduling tool supporting Oracle&lt;/a&gt;. The schedule
was glued with &lt;a href="https://www.gnu.org/software/bash/"&gt;bash&lt;/a&gt; scripts, designed
in a proprietary development environment only available for Windows, and
rolled out on Oracle machines running GNU/Linux. Neither GNU/Linux, nor
Windows using developers were fond of this situation.&lt;/li&gt;
  &lt;li&gt;Due to the high cost of a failing ETL, business also did not feel empowered
to change and/or commercially optimize it easily. This was a pretty
demotivating issue affecting both technical and business people need to work
with it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Enough blaming the former engineer. We need to get our facts right. The
aforementioned PL/SQL giant was not rolled out in a day with a big bang. This
more than a decade old ETL pipeline was developed with all the best practices
and tooling available back then. The more you dive into its source code,
navigate through commits of features spanning through years, it becomes easier
to see what went wrong and where. Now you are able to realize the patterns
that necessitated exceptional handling of certain features, of which many due
to backward-compatibility with legacy systems that have already been
deprecated or replaced by newcomers, exploded the complexity to unintended
depths. Software development is never-ending progress and axioms you base your
initial architecture on become invalidated in the course of time due to
changing business needs. Aiming for infinite flexibility comes with an
engineering cost as well, which might very well fall short of justifying such
an expense. One should also include the massive burst of data volume and its
update frequency into this list. I personally think the old ETL pipeline and
its engineers did a fantastic job. The tool served its purpose for more than a
decade and harvested an immense amount of lessons for its successor. I would
be more than happy if we as a team can also achieve to deliver such a long
living product.&lt;/p&gt;

&lt;p&gt;&lt;a name="battle-of-storage-engines"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id="the-battle-of-storage-engines"&gt;The Battle of Storage Engines&lt;/h1&gt;

&lt;p&gt;Given our functional requirements, we evaluated a couple of different ETL
pipeline storage solutions which I &lt;a href="#configuration-stream"&gt;hinted to earlier&lt;/a&gt;.
Following is the feature matrix of each candidate:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Storage Solution&lt;/th&gt;
      &lt;th&gt;Distributed&lt;/th&gt;
      &lt;th&gt;Sharded&lt;/th&gt;
      &lt;th&gt;Required Indices&lt;/th&gt;
      &lt;th&gt;Integrity Measure&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;PostgreSQL&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;One&lt;sup&gt;1&lt;/sup&gt;
&lt;/td&gt;
      &lt;td&gt;Transactions&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PostgreSQL (partitioned)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Yes&lt;sup&gt;2&lt;/sup&gt;
&lt;/td&gt;
      &lt;td&gt;One&lt;sup&gt;1&lt;/sup&gt;
&lt;/td&gt;
      &lt;td&gt;Transactions&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;MongoDB&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Yes&lt;sup&gt;3&lt;/sup&gt;
&lt;/td&gt;
      &lt;td&gt;Some&lt;sup&gt;4&lt;/sup&gt;
&lt;/td&gt;
      &lt;td&gt;Compare-and-swap&lt;sup&gt;5&lt;/sup&gt;
&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Elasticsearch&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;Compare-and-swap&lt;sup&gt;6&lt;/sup&gt;
&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; PostgreSQL &lt;code&gt;jsonb&lt;/code&gt; index covers all fields.&lt;br&gt;
&lt;sup&gt;2&lt;/sup&gt; PostgreSQL partitioning is not sharding in distributed sense, but still serves a similar purpose.&lt;br&gt;
&lt;sup&gt;3&lt;/sup&gt; MongoDB sharding requires &lt;a href="https://docs.mongodb.com/manual/sharding/#shard-keys"&gt;manual configuration&lt;/a&gt;.&lt;br&gt;
&lt;sup&gt;4&lt;/sup&gt; MongoDB requires an explicit index for each whitelisted field allowed in ETL configuration predicates.&lt;br&gt;
&lt;sup&gt;5&lt;/sup&gt; MongoDB &lt;a href="https://docs.mongodb.com/manual/core/write-operations-atomicity/"&gt;&lt;code&gt;updateMany()&lt;/code&gt; or &lt;code&gt;findAndModify()&lt;/code&gt;&lt;/a&gt; can be leveraged for the desired integrity.&lt;br&gt;
&lt;sup&gt;6&lt;/sup&gt; Elasticsearch &lt;code&gt;_version&lt;/code&gt; field can be leveraged to implement a compare-and-swap loop.&lt;/p&gt;

&lt;p&gt;&lt;a name="benchmark-setup"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="benchmark-setup"&gt;Benchmark Setup&lt;/h2&gt;

&lt;p&gt;For the benchmark, we populated each store with 33 million JSON documents of
which each weighs an average size of 2.5KB. One of the contrived fields in the
document is &lt;code&gt;search_rank&lt;/code&gt;. Later on, a file consisting of 6 million distinct
&lt;code&gt;&amp;lt;id, search_rank&amp;gt;&lt;/code&gt; pairs is streamed in batches of size 1000. For each batch,
we first fetch the old &lt;code&gt;search_rank&lt;/code&gt;s associated with the &lt;code&gt;id&lt;/code&gt;s and then bulk
update these with the new &lt;code&gt;search_rank&lt;/code&gt;s. In this scenario, what we tried to
emulate is a bulk update triggered by a configuration snapshot delta, which
is the most storage performance demanding operation in the ETL pipeline.&lt;/p&gt;

&lt;p&gt;Used test bed is a cluster composed of 6 dedicated machines with the following
specifications:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
&lt;strong&gt;CPU&lt;/strong&gt;: 16 core Intel Xeon E5-2620 v4 @ 2.10GHz&lt;/li&gt;
  &lt;li&gt;
&lt;strong&gt;Memory/Swap&lt;/strong&gt;: 128GB/16GB&lt;/li&gt;
  &lt;li&gt;
&lt;strong&gt;Disk&lt;/strong&gt;: 375GB (Intel P4800X Performance NVMe PCIe SSD)&lt;/li&gt;
  &lt;li&gt;
&lt;strong&gt;Kernel&lt;/strong&gt;: 3.10.0-693.1.1.el7.x86_64&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We further configured each store as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;: Just one PostgreSQL 9.6.10 instance containing a single
&lt;code&gt;&amp;lt;id, content&amp;gt;&lt;/code&gt; table where &lt;code&gt;content&lt;/code&gt; is of type &lt;a href="https://www.postgresql.org/docs/current/datatype-json.html#JSON-INDEXING"&gt;&lt;code&gt;jsonb&lt;/code&gt;&lt;/a&gt;.
Benchmark configured to update only the &lt;code&gt;search_rank&lt;/code&gt; attribute of the
&lt;code&gt;content&lt;/code&gt; column.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;PostgreSQL (partitioned)&lt;/strong&gt;: Same as above, but the &lt;code&gt;content&lt;/code&gt; table is
partitioned into 10 tables.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;MongoDB&lt;/strong&gt;: MongoDB 3.6 with the following configurations:&lt;/p&gt;

    &lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span class="l-Scalar-Plain"&gt;systemLog.destination&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;file&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;systemLog.logAppend&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;true&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;processManagement.fork&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;true&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;storage.engine&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;wiredTiger&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;security.authorization&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;enabled&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;replication.oplogSizeMB&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;9216&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;Note that sharding is not enabled. (More on this later.)&lt;/p&gt;

    &lt;p&gt;Similar to PostgreSQL setup, benchmark configured to update only the
&lt;code&gt;search_rank&lt;/code&gt; attribute of documents.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Elasticsearch&lt;/strong&gt;: Elasticsearch 6.3.0 with the following JVM flags:&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;-Xms30g
-Xmx30g
-Xss256k
-XX:NewRatio=3
-XX:+UseParNewGC
-XX:+UseConcMarkSweepGC
-XX:CMSInitiatingOccupancyFraction=75
-XX:+UseCMSInitiatingOccupancyOnly
-XX:+PrintGCDetails
-XX:+PrintGCDateStamps
-XX:+PrintClassHistogram
-XX:+PrintTenuringDistribution
-XX:+PrintGCApplicationStoppedTime
&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;Here JVM heap size is set to 30G due to
&lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html"&gt;compressed OOPs limitation&lt;/a&gt;.&lt;/p&gt;

    &lt;p&gt;Different from PostgreSQL and MongoDB setups, where only the &lt;code&gt;search_rank&lt;/code&gt;
attribute is updated, Elasticsearch benchmark is configured to update the
entire document. While this overkill is subject to hammer Elasticsearch way
heavier (since Elasticsearch will create quite some garbage segments waiting
to be merged and making every object nested worsens the case even more) than
other stores, it is more strategically aligned with how we want to use it in
the future.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name="benchmark-results"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="benchmark-results"&gt;Benchmark Results&lt;/h2&gt;

&lt;p&gt;Below you will see the results of the benchmark for only MongoDB and
Elasticsearch. The reason PostgreSQL results were omitted is no matter what
kind of optimization we throw at it, the benchmark always took more than 2
hours, regardless of partitioning, whereas MongoDB and Elasticsearch took a
couple of minutes.&lt;/p&gt;

&lt;style&gt;
.concurrency { text-align: center; }
.measurement { text-align: right; }
.per-batch .measurement { font-weight: bold;  }
&lt;/style&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Store&lt;/th&gt;
      &lt;th&gt;Conc.&lt;sup&gt;7&lt;/sup&gt;
&lt;/th&gt;
      &lt;th&gt;Latency&lt;/th&gt;
      &lt;th&gt;Total (s)&lt;/th&gt;
      &lt;th&gt;Fetch&lt;sup&gt;8&lt;/sup&gt; 75% (ms)&lt;/th&gt;
      &lt;th&gt;Fetch&lt;sup&gt;8&lt;/sup&gt; 99% (ms)&lt;/th&gt;
      &lt;th&gt;Fetch&lt;sup&gt;8&lt;/sup&gt; Max. (ms)&lt;/th&gt;
      &lt;th&gt;Update&lt;sup&gt;9&lt;/sup&gt; 75% (ms)&lt;/th&gt;
      &lt;th&gt;Update&lt;sup&gt;9&lt;/sup&gt; 99% (ms)&lt;/th&gt;
      &lt;th&gt;Update&lt;sup&gt;9&lt;/sup&gt; Max. (ms)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td rowspan="6"&gt;MongoDB&lt;/td&gt;
      &lt;td rowspan="2" class="concurrency"&gt;8&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td class="measurement"&gt;518&lt;/td&gt;
      &lt;td class="measurement"&gt;68&lt;/td&gt;
      &lt;td class="measurement"&gt;999&lt;/td&gt;
      &lt;td class="measurement"&gt;3380&lt;/td&gt;
      &lt;td class="measurement"&gt;64&lt;/td&gt;
      &lt;td class="measurement"&gt;2347&lt;/td&gt;
      &lt;td class="measurement"&gt;4153&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class="per-batch"&gt;
      &lt;td colspan="2"&gt;per batch&lt;/td&gt;
      &lt;td class="measurement"&gt;8&lt;/td&gt;
      &lt;td class="measurement"&gt;125&lt;/td&gt;
      &lt;td class="measurement"&gt;423&lt;/td&gt;
      &lt;td class="measurement"&gt;8&lt;/td&gt;
      &lt;td class="measurement"&gt;293&lt;/td&gt;
      &lt;td class="measurement"&gt;519&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td rowspan="2" class="concurrency"&gt;16&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td class="measurement"&gt;526&lt;/td&gt;
      &lt;td class="measurement"&gt;71&lt;/td&gt;
      &lt;td class="measurement"&gt;3082&lt;/td&gt;
      &lt;td class="measurement"&gt;7905&lt;/td&gt;
      &lt;td class="measurement"&gt;68&lt;/td&gt;
      &lt;td class="measurement"&gt;5564&lt;/td&gt;
      &lt;td class="measurement"&gt;7955&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class="per-batch"&gt;
      &lt;td colspan="2"&gt;per batch&lt;/td&gt;
      &lt;td class="measurement"&gt;4&lt;/td&gt;
      &lt;td class="measurement"&gt;193&lt;/td&gt;
      &lt;td class="measurement"&gt;494&lt;/td&gt;
      &lt;td class="measurement"&gt;4&lt;/td&gt;
      &lt;td class="measurement"&gt;348&lt;/td&gt;
      &lt;td class="measurement"&gt;497&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td rowspan="2" class="concurrency"&gt;32&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td class="measurement"&gt;518&lt;/td&gt;
      &lt;td class="measurement"&gt;61&lt;/td&gt;
      &lt;td class="measurement"&gt;6668&lt;/td&gt;
      &lt;td class="measurement"&gt;11465&lt;/td&gt;
      &lt;td class="measurement"&gt;98&lt;/td&gt;
      &lt;td class="measurement"&gt;10533&lt;/td&gt;
      &lt;td class="measurement"&gt;13784&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class="per-batch"&gt;
      &lt;td colspan="2"&gt;per batch&lt;/td&gt;
      &lt;td class="measurement"&gt;2&lt;/td&gt;
      &lt;td class="measurement"&gt;208&lt;/td&gt;
      &lt;td class="measurement"&gt;358&lt;/td&gt;
      &lt;td class="measurement"&gt;3&lt;/td&gt;
      &lt;td class="measurement"&gt;329&lt;/td&gt;
      &lt;td class="measurement"&gt;431&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td rowspan="6"&gt;Elasticsearch&lt;/td&gt;
      &lt;td rowspan="2" class="concurrency"&gt;8&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td class="measurement"&gt;251&lt;/td&gt;
      &lt;td class="measurement"&gt;278&lt;/td&gt;
      &lt;td class="measurement"&gt;423&lt;/td&gt;
      &lt;td class="measurement"&gt;798&lt;/td&gt;
      &lt;td class="measurement"&gt;94&lt;/td&gt;
      &lt;td class="measurement"&gt;186&lt;/td&gt;
      &lt;td class="measurement"&gt;412&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class="per-batch"&gt;
      &lt;td colspan="2"&gt;per batch&lt;/td&gt;
      &lt;td class="measurement"&gt;35&lt;/td&gt;
      &lt;td class="measurement"&gt;53&lt;/td&gt;
      &lt;td class="measurement"&gt;100&lt;/td&gt;
      &lt;td class="measurement"&gt;12&lt;/td&gt;
      &lt;td class="measurement"&gt;23&lt;/td&gt;
      &lt;td class="measurement"&gt;52&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td rowspan="2" class="concurrency"&gt;16&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td class="measurement"&gt;196&lt;/td&gt;
      &lt;td class="measurement"&gt;478&lt;/td&gt;
      &lt;td class="measurement"&gt;697&lt;/td&gt;
      &lt;td class="measurement"&gt;1004&lt;/td&gt;
      &lt;td class="measurement"&gt;141&lt;/td&gt;
      &lt;td class="measurement"&gt;266&lt;/td&gt;
      &lt;td class="measurement"&gt;410&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class="per-batch"&gt;
      &lt;td colspan="2"&gt;per batch&lt;/td&gt;
      &lt;td class="measurement"&gt;30&lt;/td&gt;
      &lt;td class="measurement"&gt;44&lt;/td&gt;
      &lt;td class="measurement"&gt;63&lt;/td&gt;
      &lt;td class="measurement"&gt;9&lt;/td&gt;
      &lt;td class="measurement"&gt;17&lt;/td&gt;
      &lt;td class="measurement"&gt;26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td rowspan="2" class="concurrency"&gt;32&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td class="measurement"&gt;175&lt;/td&gt;
      &lt;td class="measurement"&gt;951&lt;/td&gt;
      &lt;td class="measurement"&gt;1368&lt;/td&gt;
      &lt;td class="measurement"&gt;1515&lt;/td&gt;
      &lt;td class="measurement"&gt;214&lt;/td&gt;
      &lt;td class="measurement"&gt;331&lt;/td&gt;
      &lt;td class="measurement"&gt;828&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class="per-batch"&gt;
      &lt;td colspan="2"&gt;per batch&lt;/td&gt;
      &lt;td class="measurement"&gt;30&lt;/td&gt;
      &lt;td class="measurement"&gt;43&lt;/td&gt;
      &lt;td class="measurement"&gt;47&lt;/td&gt;
      &lt;td class="measurement"&gt;7&lt;/td&gt;
      &lt;td class="measurement"&gt;10&lt;/td&gt;
      &lt;td class="measurement"&gt;26&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;sup&gt;7&lt;/sup&gt; Number of concurrent batches.&lt;br&gt;
&lt;sup&gt;8&lt;/sup&gt; Time it takes to fetch a batch.&lt;br&gt;
&lt;sup&gt;9&lt;/sup&gt; Time it takes to update a batch.&lt;/p&gt;

&lt;p&gt;Let me share some observations from the results:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Increasing concurrency&lt;/strong&gt; improves Elasticsearch performance (up to 32
concurrent batches) but does not have much effect on MongoDB.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Elasticsearch rocked in performance&lt;/strong&gt; even though it is hammered with
the update of the entire document whereas MongoDB is just trying to update a
single attribute. Using 32 concurrent batches, it took 175s and 518s for
Elasticsearch and MongoDB, respectively, to complete the benchmark.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Elasticsearch yielded way more predictable performance&lt;/strong&gt; figures compared
to MongoDB. Note the difference between 75- and 99-percentile figures.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Elasticsearch segment merges&lt;/strong&gt; were unexpectedly pretty stable during
the runs, whereas we were anticipating it to become the bottleneck due to
high update rate. But compare-and-swap loops played over &lt;code&gt;_version&lt;/code&gt; fields
allowed for the necessary data integrity without breaking a sweat.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the time of testing, we initially were not able to enable sharding in
MongoDB due to operational obstacles on our side. Though Elasticsearch results
were such promising, to the point of even shocking the hired Elasticsearch
consultants, we decided to go with it, of which we have years of production
experience. If we would put the necessity of whitelisted configuration
predicate fields problem aside – that is, required explicit indices on what
can be queried – MongoDB could very well be a viable option as well.&lt;/p&gt;

&lt;p&gt;But, really, why Elasticsearch has a reputation of not being recommended as a
primary data store? I think it all started when the official project website
years ago contained an explicit statement admitting that Elasticsearch is not
intended to be used as a primary data store. Once, as the very owner of the
project itself, you admit this fact, it is really difficult to convince people
the other way around – even if the situation might have been improved. Later
on, published &lt;a href="https://jepsen.io/"&gt;Jepsen&lt;/a&gt; (an effort to improve the safety of
distributed databases, queues, consensus systems, etc.) reports (&lt;a href="https://aphyr.com/posts/317-call-me-maybe-elasticsearch"&gt;one in
2014-06-15 using Elasticsearch 1.1.0&lt;/a&gt;
and the other &lt;a href="https://aphyr.com/posts/323-call-me-maybe-elasticsearch-1-5-0"&gt;one in 2015-04-27 using Elasticsearch
1.5.0&lt;/a&gt;)
worsened the situation and this bad reputation disseminated over the web in
the speed of light. While this tornado DDoS’ing the entire Hackernews,
Proggit, etc. blogosphere with endless discussions in the form of &lt;i&gt;“See? I
told ya so!”&lt;/i&gt;, Elasticsearch team put up a &lt;a href="https://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html"&gt;Elasticsearch Resiliency
Status&lt;/a&gt;
page. There they started sharing (even up to today!) known resiliency
problems, including the ones found in Jepsen reports, converting them into
reproducable cases in &lt;a href="https://github.com/elastic/elasticsearch/issues/"&gt;GitHub
issues&lt;/a&gt;, and tackling them
one at a time. What else would qualify as a professional commitment if not
this one? Again, these were all back in early 2015. Our Elasticsearch
production deployments successfully managed to return with a victory from
every battle front thrown at them. It did not always feel like a walk in
the park. We had our hard times, though managed to overcome those and noted
down the experience to the book of lessons learnt. Let me share some common
practices from that collection:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
&lt;strong&gt;Security&lt;/strong&gt;: Elasticsearch does not provide any means of security
measures (encryption, etc.) out of the box. We do not use Elasticsearch to
store any sort of &lt;a href="https://en.wikipedia.org/wiki/Personally_identifiable_information"&gt;PII&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;
&lt;strong&gt;Transactions&lt;/strong&gt;: Elasticsearch does not have transaction support. Though we
work around it by performing compare-and-swap loops over the &lt;code&gt;_version&lt;/code&gt;
field.&lt;/li&gt;
  &lt;li&gt;
&lt;strong&gt;Tooling&lt;/strong&gt;: Elasticsearch tooling is… just a piece of crap. It doesn’t
have a proper development environment – you are stuck to running a fully
blown Kibana just to be able to use its arcane
&lt;a href="https://www.elastic.co/guide/en/kibana/current/console-kibana.html"&gt;Console&lt;/a&gt;.
Its Java client drags in the entire milky way of Elasticsearch artifacts
as a dependency which is a &lt;a href="https://en.wikipedia.org/wiki/Java_Classloader#JAR_hell"&gt;JAR
Hell&lt;/a&gt; time bomb
waiting to explode. Further, the recently introduced &lt;a href="https://www.elastic.co/guide/en/elasticsearch/client/java-rest/master/java-rest-high.html"&gt;high-level REST
client&lt;/a&gt;
leaks the Apache HTTP Client API models, etc. For the leaked models
and transitive dependencies, there is nothing much you can do – you just
learn to live with them. For IDE, you just keep a thick stack of HTTP
request recipes using your favorite HTTP client, e.g.,
&lt;a href="https://curl.haxx.se/2"&gt;cURL&lt;/a&gt;, &lt;a href="https://www.getpostman.com/"&gt;Postman&lt;/a&gt;,
&lt;a href="https://httpie.org/"&gt;httpie&lt;/a&gt;, etc.&lt;/li&gt;
  &lt;li&gt;
&lt;strong&gt;Documentation&lt;/strong&gt;: Elasticsearch does not have documentation; &lt;a href="https://www.postgresql.org/docs/"&gt;PostgreSQL
has documentation&lt;/a&gt;, &lt;a href="https://docs.mongodb.com/"&gt;MongoDB has
documentation&lt;/a&gt;. What Elasticsearch has is &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html"&gt;a stack
of surface-scratching blog posts served in the form of a documentation-like
website&lt;/a&gt;.
Elasticsearch also has an ocean of &lt;a href="https://stackoverflow.com/questions/tagged/elasticsearch"&gt;Stack
Overflow&lt;/a&gt;
and &lt;a href="https://discuss.elastic.co/c/elasticsearch"&gt;forum&lt;/a&gt; posts where you are
allowed to swim at your convenience. That being said, one needs to admit that
situation is improving over the time. (Yes, it was way worse!)&lt;/li&gt;
  &lt;li&gt;
&lt;strong&gt;Resiliency&lt;/strong&gt;: Yes, Elasticsearch can crash, just like another piece of
software. In order to address these emergencies, in addition to hot-standby
clusters, we take regular &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html"&gt;snapshots&lt;/a&gt;
and persist the messages processed by the ETL pipeline to a separate storage
providing efficient write and bulk read operations, e.g., PostgreSQL, Google
BigQuery, etc. In case of need, we just restore from a snapshot and replay
the necessary set of messages to recover the lost state.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Is Elasticsearch the perfect tool for the job at hand? Not really. But it is
the one closest to that. We also know how to deal with each other – just like
in any other relationship.&lt;/p&gt;

&lt;p&gt;&lt;a name="new-etl"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id="the-new-etl"&gt;The New ETL&lt;/h1&gt;

&lt;p&gt;By taking into account the ETL pipeline concerns detailed in previous
chapters, we derived a list of basic foundations that we aim to deliver:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The configuration DSL must be abstract enough to avoid &lt;del&gt;any&lt;/del&gt; too
much vendor lock-in. One must be able to represent configurations in this
DSL such that applying these on a JSON and/or the underlying storage unit
must be a matter of writing the necessary adapter classes.&lt;/li&gt;
  &lt;li&gt;The storage must allow the ETL pipeline to query the entire collection
using any possible filter combinations allowed by the configuration
predicate DSL. This is a crucial pillar in the design to enable real-time
processing of every message, both content and configuration snapshot
stream, without necessitating an ETL run over the complete collection which
used to be the case in the old ETL pipeline.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let me elaborate on how we addressed these deliverables.&lt;/p&gt;

&lt;p&gt;&lt;a name="primary-storage-elasticsearch"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="the-primary-storage-elasticsearch"&gt;The Primary Storage: Elasticsearch&lt;/h2&gt;

&lt;p&gt;The previous benchmark section already detailed the rationale behind employing
Elasticsearch as the primary storage. It is distributed and sharded by
default. It doesn’t require explicit indices on a whitelist of allowed
configuration predicate fields – every field is allowed to be queried by
default. It has no problems with querying fields containing a list of objects.
It provides sufficient leverage for data integrity via compare-and-swap loops
over &lt;code&gt;_version&lt;/code&gt; fields. It is very efficient on bulk fetches and updates,
which was totally unexpected for us. Last, but not least, it is our bread and
butter in search and we have plenty of experience with it.&lt;/p&gt;

&lt;p&gt;&lt;a name="configuration-dsl-json-groovy"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id="the-configuration-dsl-json-and-groovy"&gt;The Configuration DSL: JSON and Groovy&lt;/h2&gt;

&lt;p&gt;In the case of configuration DSL, we wanted to stop the plague of PL/SQL
leakage all around the code base. For this purpose, we decided to go with the
model depicted below.&lt;/p&gt;

&lt;p&gt;&lt;img src="dsl.jpg" alt="The New Configuration DSL"&gt;&lt;/p&gt;

&lt;p&gt;Here we replaced SQL WHERE clauses, which were used to represent configuration
predicates in the old ETL pipeline, with JSON describing the structure of
the predicate. This new predicate representation resembling the Elasticsearch
filters is translated to individual executors matching against either JSON
(coming from the real-time content stream) or the storage engine, that is,
Elasticsearch. Note that the way we used to represent the predicate is
independent of medium (JSON, Elasticsearch, etc.) it is executed against such
that we even implemented a MongoDB adapter at some point. An example
configuration predicate JSON is show below:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"nested"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="nt"&gt;"path"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"content"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"attribute"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
  &lt;span class="nt"&gt;"filter"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"and"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"filters"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
      &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"nested"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="nt"&gt;"path"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"gpc"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="nt"&gt;"filter"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"and"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="nt"&gt;"filters"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
              &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"equals"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="nt"&gt;"path"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"family_id"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
              &lt;span class="nt"&gt;"value"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1234"&lt;/span&gt;
            &lt;span class="p"&gt;},&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
              &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"equals"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="nt"&gt;"path"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"chunk_id"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
              &lt;span class="nt"&gt;"value"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"5678"&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
          &lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="p"&gt;},&lt;/span&gt;
      &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"nested"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="nt"&gt;"path"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"authors"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="nt"&gt;"filter"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"and"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="nt"&gt;"filters"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
              &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"equals"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="nt"&gt;"path"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"fname"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
              &lt;span class="nt"&gt;"value"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Volkan"&lt;/span&gt;
            &lt;span class="p"&gt;},&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
              &lt;span class="nt"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"equals"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="nt"&gt;"path"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"lname"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
              &lt;span class="nt"&gt;"value"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Yazici"&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
          &lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As depicted above, we split the configuration mutation model into two
abstractions: &lt;em&gt;extension&lt;/em&gt; and &lt;em&gt;functional extension&lt;/em&gt;. An extension is the
simplest form of mutation that generally applies to more than 90% of the
available configurations. It is basically a JSON object that is upon execution
expected to be merged into the original source. A simple example is as
follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-json"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"category"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"books"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Functional extensions are built to address complex configuration mutations.
There we employed &lt;a href="http://www.groovy-lang.org/"&gt;Groovy&lt;/a&gt; after experimenting
with some other candidates, e.g., JavaScript (&lt;a href="https://www.oracle.com%0A/technetwork/articles/java/jf14-nashorn-2126515.html"&gt;Nashorn&lt;/a&gt;, which is &lt;a href="http://openjdk.java.net/jeps/335"&gt;planned to be
dropped&lt;/a&gt;), Python
(&lt;a href="http://www.jython.org/"&gt;Jython&lt;/a&gt;), Ruby (&lt;a href="https://www.jruby.org/"&gt;JRuby&lt;/a&gt;),
etc. The main drivers for us to pick Groovy are as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It supports direct access to Java data structures (e.g., &lt;code&gt;java.util.Map&lt;/code&gt;)
without any intermediate translations, hence has no problems processing
thousands of mutations on a single core.&lt;/li&gt;
  &lt;li&gt;It is widely adopted to an extent that in the future we might opt for
running it against the storage engine.&lt;/li&gt;
  &lt;li&gt;Its runtime performance is on par with the rest of the candidates.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That being said, the decision of Groovy creates a JVM vendor lock-in for the
ETL pipeline, though we do not anticipate this to be a problem for at least
the coming decade.&lt;/p&gt;

&lt;p&gt;A sample functional extension is given below.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-groovy"&gt;&lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;def&lt;/span&gt; &lt;span class="n"&gt;diskCapacityBytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"disk_capacity_bytes"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="kt"&gt;def&lt;/span&gt; &lt;span class="n"&gt;diskCapacityGigabytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;diskCapacityBytes&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;e9&lt;/span&gt;
    &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"disk_capacity_gigabytes"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;diskCapacityGigabytes&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a name="conclusion"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Implementing an e-commerce search engine is a tough business. The part of the
iceberg under the water level – that is, the ETL pipeline – is not less than
that. In this post, I tried to share the lessons we piled up in the
implementation and maintenance of our decade-old ETL pipeline and how we
cultivated these to come up with something new. I attempted to explain how the
choice for the configuration DSL and the used primary storage engine has the
uttermost implication on the rest of the components of the architecture.
Elasticsearch has already been serving us pretty well in the search gateway.
Taking a step further and employing it in the ETL was a substantially
unconventional idea that gave the shivers to every engineer involved in the
decision. But the careful consideration and evaluation of potential candidates
paid off: It worked! So when you visit &lt;a href="https://bol.com"&gt;bol.com&lt;/a&gt; next time,
you will know that the Elasticsearch in the ETL pipeline – in addition to
many other Elasticsearch using services involved – cooked that warm page for
you seconds ago.&lt;/p&gt;

&lt;p&gt;&lt;a name="acknowledgements"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id="acknowledgements"&gt;Acknowledgements&lt;/h1&gt;

&lt;p&gt;I would like thank to &lt;a href="https://twitter.com/bbuharali"&gt;Berkay Buharalı&lt;/a&gt;,
Lourens Heijs, &lt;a href="https://twitter.com/wvl0"&gt;William Leese&lt;/a&gt;, &lt;a href="https://almer.tigelaar.net/"&gt;Almer S.
Tigelaar&lt;/a&gt;, Leon Widdershoven, and &lt;a href="https://twitter.com/maurice_zeijen"&gt;Maurice
Zeijen&lt;/a&gt; for their valuable feedback in
bringing the post to its final form.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2018-02-17://blog/post/2018/02/17/varnishing-search-performance/</id>
    <title type="html">Varnishing Search Performance</title>
    <published>2018-02-17T20:42:00Z</published>
    <updated>2018-02-17T20:42:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2018/02/17/varnishing-search-performance/"/>
    <content type="html">
&lt;p&gt;This week &lt;a href="http://bol.com"&gt;bol.com&lt;/a&gt; hosted an &lt;a href="https://www.meetup.com/Elastic-NL/"&gt;Elastic User Group
NL&lt;/a&gt; meetup titled &lt;a href="https://www.meetup.com/Elastic-NL/events/247114723/"&gt;bol.com: Changing the
(search) engine of a racecar going 300 km/h&lt;/a&gt;.
The abstract of the presentations were as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Almost 2 years ago bol.com decided to move towards an
Elasticsearch-powered search engine. But how do you approach such a
project? Who do you involve and what do you need to (not) do? The
engineers at bol.com would like to share their experiences about this
migration, in 4 short talks.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And among those 4 short talks, I took the stage with &lt;em&gt;Varnishing Search Performance&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Searching is &lt;em&gt;peanuts&lt;/em&gt;. You setup your Elasticsearch cluster (or better
find a SaaS partner) and start shooting your search queries against it.
Well… Not really. If we put the biblical data ingestion story aside, it
won’t take long to realize that even moderately complicated queries can
become a bottleneck for those aiming for &amp;lt;50ms query performance.
Combine a couple of aggregations, double that for facets of range type,
add your grandpa’s boosting factors to the scoring, and there you go;
now you are a search query performance bottleneck owner too! Maybe I am
exaggerating a bit. Why not just start throwing some caches in front of
it? Hrm… We actually thought of that and did so. Though it brought a
mountain of problems along with itself, and there goes my story.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The slides are available in &lt;a href="varnishing-search-performance.pdf"&gt;PDF&lt;/a&gt; and
&lt;a href="varnishing-search-performance-org.odp"&gt;ODP&lt;/a&gt; formats.&lt;/p&gt;

&lt;iframe src="//www.slideshare.net/slideshow/embed_code/key/4h5JWHH25nHGa4" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;
&lt;/iframe&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2018-02-09://blog/post/2018/02/09/netty-in-action/</id>
    <title type="html">Notes on "Netty in Action"</title>
    <published>2018-02-09T20:34:00Z</published>
    <updated>2018-02-09T20:34:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2018/02/09/netty-in-action/"/>
    <content type="html">
&lt;p&gt;Those who had priviledge to read my &lt;a href="/blog/post/2017/04/18/inter-service-comm/"&gt;frustration chronicles on intra-microservice communication&lt;/a&gt; would easily
recall me pointing my finger to Java Platform SE guys for not shipping a
proper HTTP client. There my fury went to an extent calling it as one of the
closest candidates for the billion dollar mistake. Unfortunately screaming out
loud in a blog post does not give much of a relief, because it doesn’t take
more than a month for me to find myself in precisely the same technical
mudpot. Indeed after a couple of months later I wrote that post, I was chasing
yet another performance problem in one of our aggregation services. In
essence, each incoming HTTP request is served by aggregating multiple sources
collected again over HTTP. This simple fairy tale architecture gets
slaughtered on production by 200 Tomcat threads intertwined with Rx
computation and I/O threads resting in the shades of a dozen other thread
pools dedicated for so-called-asynchronous HTTP clients for aggregated remote
services. And I saved the best for last: there were leaking &lt;code&gt;TIME_WAIT&lt;/code&gt;
sockets.&lt;/p&gt;

&lt;p&gt;All of a sudden the question occurred to me like the roar of rolling boulders
down a steep hill in a far distance: What is the lowest level that I can plumb
a networking application in Java without dealing with protocol intricacies.
Put another way, is there a foundational abstraction exposing both the lowest
(channel with I/O streams) and highest (HTTP headers and body) levels that are
in reach? I rode both Java OIO and NIO (that is, old- and new-I/O) horses in
the past and fell off enough to learn it the hard way that they are definitely
not feasible options in this case. The first attempt in the search of a cure
in Google introduces you to &lt;a href="http://netty.io/"&gt;Netty&lt;/a&gt;. If you dig long enough,
you also stumble upon &lt;a href="http://mina.apache.org/"&gt;Apache Mina&lt;/a&gt; too. Netty is
popular enough in the Java world that it is highly likely you are an indirect
consumer of it, unless you are already directly using it. I was aware of its
presence like dark matter in every single network application that I wrote,
though I have never considered to use it directly. Checking the Netty website
after dealing with crippled network applications at hand revealed an
enlightenment within me: &lt;em&gt;Hey! I can purpose this to implement some sort of
RPC mechanism using Protocol Buffers in HTTP 2.0 request payloads!&lt;/em&gt; Though
further investigation swipes the dust from the footsteps of giants who had
followed the same path: Google (&lt;a href="https://grpc.io/"&gt;gRPC&lt;/a&gt;), Facebook
(&lt;a href="https://github.com/facebook/nifty"&gt;Nifty&lt;/a&gt;), Twitter
(&lt;a href="https://twitter.github.io/finagle/"&gt;Finagle&lt;/a&gt;), etc. This finding while
crushing my first excitement, later on left its place to the confidence of
getting confirmed that I am on the right path.&lt;/p&gt;

&lt;p&gt;I have always heard good things about both Netty and its community. I have
already been sneakily following the
&lt;a href="http://normanmaurer.me/presentations/"&gt;presentations&lt;/a&gt; and &lt;a href="https://twitter.com/normanmaurer"&gt;Twitter
updates&lt;/a&gt; of &lt;a href="http://normanmaurer.me/"&gt;Norman
Maurer&lt;/a&gt;, the Netty shepherd as of date. Though what
triggered me for diving deep with Netty has become the following tweet:&lt;/p&gt;

&lt;blockquote class="twitter-tweet" data-lang="en"&gt;
&lt;p lang="en" dir="ltr"&gt;Challenge accepted! First step is done. Next: Cover to cover study. &lt;a href="https://t.co/Gnfhbi6Ko0"&gt;pic.twitter.com/Gnfhbi6Ko0&lt;/a&gt;&lt;/p&gt;— Volkan Yazıcı (@yazicivo) &lt;a href="https://twitter.com/yazicivo/status/954366672751689728?ref_src=twsrc%5Etfw"&gt;January 19, 2018&lt;/a&gt;
&lt;/blockquote&gt;

&lt;p&gt;Norman Maurer has always been kind and encouraging to new contributors. So my
plan is to turn this into a relation with mutual benefit: I can contribute and
get tutored while doing that so.&lt;/p&gt;

&lt;h1 id="netty-in-action"&gt;Netty in Action&lt;/h1&gt;

&lt;p&gt;&lt;a href="https://www.manning.com/books/netty-in-action"&gt;The book&lt;/a&gt; (2016 press date) is
definitely a must read for anyone planning to use Netty. It lays out Netty
fundamentals like channels, handlers, encoders, etc. in detail. That being
said, I have got the impression that the content is mostly curated for
beginners. For instance, dozens of pages (and an appendix) are spent (wasted?)
for a Maven crash course, not to mention the space wasted by Maven command
ouputs shared. This felt a little bit disappointing considering the existing
audience of Netty in general. Who would really read a book about Netty? You
have probably had your time with OIO/NIO primitives or client/server
frameworks in the market. You certainly don’t want to use yet another library
that promises to make all your problems disappear. So I don’t think you can be
qualified as a novice in this battle anymore, and you are indeed in the search
of a scalpel rather than a swiss army knife. Nevertheless, I still think the
book eventually managed to succeed in finding a balance between going too deep
and just scratching the surface.&lt;/p&gt;

&lt;h2 id="things-that-are-well-done"&gt;Things that are well done&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;I really enjoyed the presented &lt;strong&gt;historical perspective&lt;/strong&gt; on the development
of Java platforms’ networking facilities and Netty itself. Found it quite
valuable and wanted to read more and more!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Emphasis on &lt;strong&gt;&lt;code&gt;ByteBuf&lt;/code&gt;&lt;/strong&gt; was really handy. Later on I learnt that there are
people using Netty just for its sound &lt;code&gt;ByteBuf&lt;/code&gt; implementation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Almost every single conscious decision within the shared &lt;strong&gt;code snippets are
explained in detail&lt;/strong&gt;. While this felt like quite some noise in the
beginning, later on it turned out be really helpful – especially while
manually updating &lt;code&gt;ByteBuf&lt;/code&gt; reference counts.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Presented &lt;strong&gt;case studies&lt;/strong&gt; were quite interesting to read and inspiring too.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="things-that-could-have-been-improved"&gt;Things that could have been improved&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;I had big hopes to read about how to implement an HTTP client with
&lt;strong&gt;connection pool&lt;/strong&gt; support. I particularly find this feature inevitable in a
networking application and often not consumed wisely. Though there wasn’t a
single section mentioning about connection pooling of any sort.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As someone who had studied &lt;a href="http://normanmaurer.me/presentations/"&gt;Norman Maurer’s
presentations&lt;/a&gt;, I was expecting to
see waaaay more practical tips about &lt;strong&gt;GC considerations&lt;/strong&gt;, updating &lt;strong&gt;socket
options&lt;/strong&gt; (&lt;code&gt;TCP_NO_DELAY&lt;/code&gt;, &lt;code&gt;SO_SNDBUF&lt;/code&gt;, &lt;code&gt;SO_RCVBUF&lt;/code&gt;, &lt;code&gt;SO_BACKLOG&lt;/code&gt;, etc.),
mitigating &lt;strong&gt;&lt;code&gt;TIME_WAIT&lt;/code&gt;&lt;/strong&gt; socket problems, and Netty best practices. Maybe
adding this content would have doubled the size of the book, though I still
think a book on Netty is incomplete without such practical tips.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Many inbound requests trigger multiple I/O operations in a typical network
application. It is crucial to not let these operatins block a running thread,
which Netty is well aware of and hence ships a fully-fledged &lt;code&gt;EventExecutor&lt;/code&gt;
abstraction. This crucial detail is mentioned in many places within the book,
though none gave a concrete example. Such a common thing could have been
demonstrated by an example.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id="notes"&gt;Notes&lt;/h1&gt;

&lt;p&gt;I always take notes while reading a book. Let it be a grammar mistake, code
typo, incorrect or ambiguous information, thought provoking know-how,
practical tip, etc. You name it. Here I will share them in page order. I will
further classify my notes in 3 groups: &lt;span class="note-mistake"&gt;mistakes&lt;/span&gt;,
&lt;span class="note-improvement"&gt;improvements&lt;/span&gt;,
&lt;span class="note-question"&gt;questions&lt;/span&gt;, and
&lt;span class="note-other"&gt;other&lt;/span&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p19, Listing 2.1]&lt;/span&gt; Why did we use
&lt;code&gt;ctx.writeAndFlush(Unpooled.EMPTY_BUFFER)&lt;/code&gt;   rather than just calling
&lt;code&gt;ctx.flush()&lt;/code&gt;?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p21, Listing 2.2]&lt;/span&gt; Typo in
&lt;code&gt;throws Exceptio3n&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p49, Section 4.3.1]&lt;/span&gt;
The listed items&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;ul&gt;
        &lt;li&gt;A new &lt;code&gt;Channel&lt;/code&gt; was accepted and is ready.&lt;/li&gt;
        &lt;li&gt;A &lt;code&gt;Channel&lt;/code&gt; connection …&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;are an identical repetition of Table 4.3.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p60]&lt;/span&gt; &lt;code&gt;CompositeByteBuf&lt;/code&gt; has the
following remark:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Note that Netty optimizes socket I/O operations that employ
&lt;code&gt;CompositeByteBuf&lt;/code&gt;, eliminating whenever possible the performance and
memory usage penalties that are incurred with JDK’s buffer implementation.
This optimization takes place in Netty’s core code and is therefore not
exposed, but you should be aware of its impact.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;Interesting. Good to know. I should be aware of &lt;em&gt;its impact&lt;/em&gt;. But how can
I measure and relate this impact? Maybe I am just nitpicking, tough I would
love to hear a little bit more.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p77, Table 6.3]&lt;/span&gt;
&lt;code&gt;channelWritabilityChanged()&lt;/code&gt; method of &lt;code&gt;ChannelInboundHandler&lt;/code&gt;… How come
an inbound channel can have a writability notion? I would have expected an
inbound channel to be just readable.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p78, Section 6.1.4]&lt;/span&gt; Starts with
some really intriguing paragraph:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;A powerful capability of &lt;code&gt;ChannelOutboundHandler&lt;/code&gt; is to defer an operation
or event on demand, which allows for sophisticated approaches to request
handling. If writing to the remote peer is suspended, for example, you can
defer flush operations and resume them later.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;Though it ends here. No more explanations, not even a single example, etc.
A total mystery.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p79, Table 6.4]&lt;/span&gt; &lt;code&gt;read()&lt;/code&gt; method of a
&lt;code&gt;ChannelOutboundHandler&lt;/code&gt;… Similar to &lt;code&gt;ChannelInboundHandler#channelWritabilityChanged()&lt;/code&gt;,
how come an outbound channel can have a read method? What are we reading
that is supposed to be already originating from us and destined to a remote
peer?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p79, Section 6.1.4]&lt;/span&gt;
It goes as follows:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;&lt;strong&gt;&lt;code&gt;ChannelPromise&lt;/code&gt; vs. &lt;code&gt;ChannelFuture&lt;/code&gt;&lt;/strong&gt; Most of the methods in
&lt;code&gt;ChannelOutboutHandler&lt;/code&gt; take a &lt;code&gt;ChannelPromise&lt;/code&gt; argument to be notified
when the operation completes. &lt;code&gt;ChannelPromise&lt;/code&gt; is a subinterface of
&lt;code&gt;ChannelFuture&lt;/code&gt; that defines the writable methods, such as &lt;code&gt;setSuccess()&lt;/code&gt;
or &lt;code&gt;setFailure()&lt;/code&gt;, thus making &lt;code&gt;ChannelFuture&lt;/code&gt; immutable.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;Ok, but why? I know the difference between a &lt;code&gt;Future&lt;/code&gt; and a &lt;code&gt;Promise&lt;/code&gt;, though
I still cannot see the necessity for outbound handlers to employ &lt;code&gt;Promise&lt;/code&gt;
instead of a &lt;code&gt;Future&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p84, Listing 6.5]&lt;/span&gt; While adding handlers
to a pipeline, what happens in the case of a name conflict?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p84]&lt;/span&gt; A remark is dropped on the
&lt;strong&gt;&lt;code&gt;ChannelHandler&lt;/code&gt; execution and blocking&lt;/strong&gt; subject. Just in time! Though
it misses a demonstration.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p86, Listing 6.9]&lt;/span&gt; Again a &lt;code&gt;read()&lt;/code&gt;
method for the outbound operations of a &lt;code&gt;ChannelPipeline&lt;/code&gt;. I am really
puzzled on the notion of reading from an outbound channel.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p94, Listing 6.13]&lt;/span&gt; What happens when
a &lt;code&gt;ChannelFuture&lt;/code&gt; completes before adding a listener to it?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p95, Section 6.5]&lt;/span&gt; Last paragraph goes
like this:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;The next chapter will focus on Netty’s codec abstraction, which makes
writing protocol encoders and decoders much easier than using the
underlying &lt;code&gt;ChannelHandler&lt;/code&gt; implementations directly.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;Though next chapter focuses on &lt;code&gt;EventLoop&lt;/code&gt; and threading model.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p102, Listing 7.3]&lt;/span&gt; Speaking of
scheduling &lt;code&gt;Runnable&lt;/code&gt;s to a channel’s event loop, what if channel gets
closed before triggering the scheduled tasks?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p103]&lt;/span&gt; Page starts with the
following last paragraph:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;These examples illustrate the performance gain that can be achieved
by taking advantage of Netty’s scheduling capabilities.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;Really? Netty’s scheduling capabilities are shown by using each function in
isolation. Though I still don’t have a clue on how these capabilities can be
purposed for a performance gain. This is a &lt;strong&gt;common problem throughout the
book&lt;/strong&gt;: The innocent flashy statement hangs in the air, waiting for a
demonstration that shares some insight distilled by experience.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p104, Figure 7.4]&lt;/span&gt; The caption of figure
is as follows:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;&lt;code&gt;EventLoop&lt;/code&gt; allocation for non-blocking transports (such as NIO and AIO)&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;AIO? Looks like a typo.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p107]&lt;/span&gt; Chapter starts with the following
opening paragraph:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Having studied &lt;code&gt;ChannelPipeline&lt;/code&gt;s, &lt;code&gt;ChannelHandler&lt;/code&gt;s, and codec classes in
depth, …&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;Nope. Nothing has been mentioned so far about codec classes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p112]&lt;/span&gt; It is explained that, in the
context of &lt;code&gt;Bootstrap&lt;/code&gt;, &lt;code&gt;bind()&lt;/code&gt;   and &lt;code&gt;connect()&lt;/code&gt; can throw
&lt;code&gt;IllegalStateException&lt;/code&gt; if some combination of   &lt;code&gt;group()&lt;/code&gt;, &lt;code&gt;channel()&lt;/code&gt;,
&lt;code&gt;channelHandler()&lt;/code&gt;, and/or &lt;code&gt;handler()&lt;/code&gt; method calls   is missing. Similarly,
calling &lt;code&gt;attr()&lt;/code&gt; after &lt;code&gt;bind()&lt;/code&gt; has no effect. I personally find such
abstractions poorly designed. I would rather have used the &lt;a href="https://immutables.github.io/immutable.html#staged-builder"&gt;staged builder
pattern&lt;/a&gt; and
avoid such intricacies at compile-time.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p117, Listing 8.6]&lt;/span&gt; The 2nd argument to
&lt;code&gt;Bootstrap#group()&lt;/code&gt; looks like a typo.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p120]&lt;/span&gt; Check this end of chapter
summary out:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;In this chapter you learned how to bootstrap Netty server and client
applications, including those that use connectionless protocols. We
covered a number of special cases, including bootstrapping client channels
in server applications and using a &lt;code&gt;ChannelInitializer&lt;/code&gt; to handle the
installation of multiple &lt;code&gt;ChannelHandler&lt;/code&gt;s during bootstrapping. You saw
how to specify configuration options on channels and how to attach
information to a channel using attributes. Finally, you learned how to
shut down an application gracefully to release all resources in an
orderly fashion.&lt;/p&gt;

      &lt;p&gt;In the next chapter we’ll examine the tools Netty provides to help you
test your &lt;code&gt;ChannelHandler&lt;/code&gt; implementations.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;I have always found such summaries useless, since it is a repetition of
the chapter introduction, and hence a waste of space. Rather just
give crucial take aways, preferably in a digestible at a glimpse form.
For instance, &lt;em&gt;use &lt;code&gt;EventLoopGroup.shutdownGracefully()&lt;/code&gt;&lt;/em&gt;, etc.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p121]&lt;/span&gt; I suppose &lt;em&gt;Unit Testing&lt;/em&gt;
chapter used to come after &lt;em&gt;Codecs&lt;/em&gt; in previous prints and the authors
have moved it to an earlier stage to establish a certain coherence in
the introductory chapters. Though, reading &lt;em&gt;Codecs&lt;/em&gt; reveals that there
is close to 70% overlap in content, which feels like a poorly structured
flow. I see the value in authors’ attempt, though there is quite some
room for improvement via tuning the break down of chapters.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p124, Section 9.2.1]&lt;/span&gt;
&lt;code&gt;ByteToMessageDecoder&lt;/code&gt; is used before explained. (See my remark above.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p127]&lt;/span&gt; The following bullets&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Here are the steps executed in the code:&lt;/p&gt;

      &lt;ol&gt;
        &lt;li&gt;Writes negative 4-byte integers to a new &lt;code&gt;ByteBuf&lt;/code&gt;.&lt;/li&gt;
        &lt;li&gt;Creates an &lt;code&gt;EmbeddedChannel&lt;/code&gt; …&lt;/li&gt;
      &lt;/ol&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;is a repetition of the descriptions available in Listing 9.4.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p138, Listing 10.3]&lt;/span&gt; Comma missing
after &lt;code&gt;Integer msg&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p141]&lt;/span&gt; Why do
&lt;code&gt;MessageToMessage{Encoder,Decoder}&lt;/code&gt; classes do not have an output type,
but just &lt;code&gt;Object&lt;/code&gt;? How do you ensure type safety while chaining them
along a pipeline?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p142, Listing 10.6]&lt;/span&gt; Comma missing
after &lt;code&gt;Integer msg&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p145, Listing 10.7]&lt;/span&gt; Constructor of
&lt;code&gt;MyWebSocketFrame&lt;/code&gt; is named incorrectly.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p151, Section 11.2]&lt;/span&gt; I think
&lt;em&gt;Building Netty HTTP/HTTPS applications&lt;/em&gt; deserves its own chapter. And
a very important subject is missing: connection pooling.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p157, Listing 11.6]&lt;/span&gt; While building
the WebSocket pipeline, which handler addresses ping/pong frames?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p159, Table 11.4]&lt;/span&gt; The first sentence
in the description of &lt;code&gt;WriteTimeoutHandler&lt;/code&gt; is identical to the one in
&lt;code&gt;ReadTimeoutHandler&lt;/code&gt;. Supposedly a copy-paste side-effect.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p171]&lt;/span&gt; Check out the first paragraph:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;WebSocket is an advanced network protocol that has been developed to
improve the performance and responsiveness of web applications. We’ll
explore Netty’s support for &lt;em&gt;each of them&lt;/em&gt; by writing a sample
application.&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;Each of them? Who are they?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p177]&lt;/span&gt; &lt;em&gt;The call to &lt;code&gt;retain()&lt;/code&gt; is
needed because after &lt;code&gt;channelRead()&lt;/code&gt; …&lt;/em&gt; → &lt;em&gt;The call to &lt;code&gt;retain()&lt;/code&gt;
is needed because after &lt;code&gt;channelRead0()&lt;/code&gt; …&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p178, Table 12.1]&lt;/span&gt; Identical to
Table 11.3.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p181, Figure 12.3]&lt;/span&gt;
&lt;code&gt;ChunkedWriteHandler&lt;/code&gt; is missing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p183, Listing 12.4]&lt;/span&gt; There the shutdown
of the chat server is realized via &lt;code&gt;Runtime.getRuntime().addShutdownHook()&lt;/code&gt;.
Is this a recommended practice?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p189]&lt;/span&gt; &lt;em&gt;Figure 14.1 presents a high-level
view of the …&lt;/em&gt; → &lt;em&gt;Figure 13.1&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p189]&lt;/span&gt; &lt;em&gt;Listing 14.1 shows the details
of this simple POJO.&lt;/em&gt; → &lt;em&gt;Listing 13.1&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p190, Listing 13.1]&lt;/span&gt; &lt;code&gt;received&lt;/code&gt;
field is not used at all. Could be removed to increase clarity.
Interestingly, the field is not even encoded.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p191, Table 13.1]&lt;/span&gt;
&lt;code&gt;extendsDefaultAddressedEnvelope&lt;/code&gt; → &lt;code&gt;extends DefaultAddressedEnvelope&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p191]&lt;/span&gt; &lt;em&gt;Figure 14.2 shows the
broadcasting of three log …&lt;/em&gt; → &lt;em&gt;Figure 13.2&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p192]&lt;/span&gt; &lt;em&gt;Figure 14.3 represents
a high-level view of the …&lt;/em&gt; → &lt;em&gt;Figure 13.3&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p192, Listing 13.2]&lt;/span&gt; A &lt;code&gt;byte[] file&lt;/code&gt;
and &lt;code&gt;byte[] msg&lt;/code&gt; pair is encoded as follows:&lt;/p&gt;

    &lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeBytes&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeBytes&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LogEvent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;SEPARATOR&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeBytes&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;Later on each entry is read back by splitting at &lt;code&gt;LogEvent.SEPARATOR&lt;/code&gt;. What
if &lt;code&gt;file&lt;/code&gt; contains &lt;code&gt;LogEvent.SEPARATOR&lt;/code&gt;? I think this is a bad encoding
practice. I would rather do:&lt;/p&gt;

    &lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeInt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;length&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeBytes&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeInt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;length&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;writeBytes&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-question"&gt;[p194, Listing 13.3]&lt;/span&gt; Is there a
constant for &lt;code&gt;255.255.255.255&lt;/code&gt; broadcast address?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p195]&lt;/span&gt; &lt;em&gt;Figure 14.4 depicts the
&lt;code&gt;ChannelPipeline&lt;/code&gt; of the &lt;code&gt;LogEventonitor&lt;/code&gt; …&lt;/em&gt; → &lt;em&gt;Figure 13.4&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p196]&lt;/span&gt; Check this out:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;The &lt;code&gt;LogEventHandler&lt;/code&gt; prints the &lt;code&gt;LogEvent&lt;/code&gt;s in an easy-to-read
format that consists of the following:&lt;/p&gt;

      &lt;ul&gt;
        &lt;li&gt;The received timestamp in milliseconds.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;Really? I did not know epoch timestamps were &lt;em&gt;easy-to-read&lt;/em&gt;. Maybe for some
definition of easy-to-read.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p195]&lt;/span&gt; &lt;em&gt;Now we need to install our
handlers in the &lt;code&gt;ChannelPipeline&lt;/code&gt;, as seen in figure 14.4.&lt;/em&gt; →
&lt;em&gt;Figure 13.4&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p205]&lt;/span&gt; &lt;em&gt;Approach A, optimistic and
apparently simpler (figure 15.1)&lt;/em&gt; → &lt;em&gt;figure 14.1&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p206]&lt;/span&gt; Half of the page is spent
for justifying Droplr’s preference of approach B (safe and complex) over
approach A (optimistic and simpler). Call me an idiot, but I am not sold
to these arguments that the former approach is less safe.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p207]&lt;/span&gt; Type of &lt;code&gt;pipelineFactory&lt;/code&gt;
is missing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p210]&lt;/span&gt; There is a bullet for
tuning JVM. This on its own could have been a really interesting chapter
of this book.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-other"&gt;[p213]&lt;/span&gt; Firebase is indeed implementing
TCP-over-long-polling. I wonder if there exists any Java libraries that
implements user-level TCP over a certain channel abstraction.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p214]&lt;/span&gt; &lt;em&gt;Figure 15.4 demonstrates
how the Firebase long-polling …&lt;/em&gt; → &lt;em&gt;Figure 14.4&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p215]&lt;/span&gt; &lt;em&gt;Figure 15.5 illustrates
how Netty lets Firebase respond to …&lt;/em&gt; → &lt;em&gt;Figure 14.5&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p216]&lt;/span&gt; &lt;em&gt;… can start as soon as
byes come in off the wire.&lt;/em&gt; → &lt;em&gt;bytes&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p217, Listing 14.3]&lt;/span&gt; Last parenthesis
is missing:&lt;/p&gt;

    &lt;pre&gt;&lt;code class="language-scala"&gt;&lt;span class="n"&gt;rxBytes&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readableBytes&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;
                          &lt;span class="n"&gt;tryFlush&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ctx&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p217, Listing 14.3]&lt;/span&gt; 70% of the
intro was about implementing a control flow over long polling, though the
shared code snippet is about totally something else and almost irrelevant.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p223]&lt;/span&gt; &lt;em&gt;In referring to figure 15.1,
note that two paths …&lt;/em&gt; → &lt;em&gt;figure 14.6&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p229]&lt;/span&gt; &lt;em&gt;This request/execution flow is
shown in figure 16.1.&lt;/em&gt; → &lt;em&gt;figure 15.1&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p230]&lt;/span&gt; &lt;em&gt;Figure 16.2 shows how pipelined
requests are handled …&lt;/em&gt; → &lt;em&gt;Figure 15.2&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p230]&lt;/span&gt; &lt;em&gt;…, in the required order. See
figure 16.3.&lt;/em&gt; → &lt;em&gt;figure 15.3&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p232]&lt;/span&gt; &lt;em&gt;That simple flow (show in figure
16.4) works…&lt;/em&gt; → &lt;em&gt;figure 15.4&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p232]&lt;/span&gt; &lt;em&gt;The client call is dispatched
to the Swift library, …&lt;/em&gt; What is Swift library? Was not explained anywhere.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p232]&lt;/span&gt; &lt;em&gt;This is the flow shown in figure
16.5.&lt;/em&gt; → &lt;em&gt;figure 15.5&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-other"&gt;[p234]&lt;/span&gt; This is a really interesting piece:&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Before &lt;a href="https://github.com/facebook/nifty"&gt;Nifty&lt;/a&gt;, many of our major Java
services at Facebook used an older, custom NIO-based Thrift server
implementation that works similarly to Nifty. That implementation is an
older codebase that had more time to mature, but because its asynchronous
I/O handling code was built from scratch, and because Nifty is built on
the solid foundation of Netty’s asynchronous I/O framework, it has had
many fewer problems.&lt;/p&gt;

      &lt;p&gt;One of our custom message queuing services had been built using the older
framework, and it started to suffer from a kind of socket leak. A lot of
connections were sitting around in &lt;code&gt;CLOSE_WAIT&lt;/code&gt; state, meaning the server
had received a notification that the client had closed the socket, but the
server never reciprocated by making its own call to close the socket. This
left the sockets in a kind of &lt;code&gt;CLOSE_WAIT&lt;/code&gt; limbo.&lt;/p&gt;

      &lt;p&gt;The problem happened very slowly; across the entire pool of machines
handling this service, there might be millions of requests per second,
but usually only one socket on one server would enter this state in an
hour. It wasn’t an urgent issue because it took a long time before a
server needed a restart at that rate, but it also complicated tracking
down the cause. Extensive digging through the code didn’t help much
either: initially several places looked suspicious, but everything
ultimately checked out and we didn’t locate the problem.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-mistake"&gt;[p238]&lt;/span&gt; &lt;em&gt;Figure 16.6 shows the
relationship between …&lt;/em&gt; → &lt;em&gt;figure 15.6&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p239, Listing 15.2]&lt;/span&gt; All presented
Scala code in this chapter is over-complicated and the complexity does not
serve any purpose except wasting space and increasing cognitive load. For
instance, why does &lt;code&gt;ChannelConnector&lt;/code&gt; extend
&lt;code&gt;(SocketAddress =&amp;gt; Future[Transport[In, Out]])&lt;/code&gt; rather than just being a
simple method?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;span class="note-improvement"&gt;[p239]&lt;/span&gt; &lt;em&gt;This factory is provided a
&lt;code&gt;ChannelPipelineFactory&lt;/code&gt;, which is …&lt;/em&gt; What is &lt;em&gt;this factory&lt;/em&gt;?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;style type="text/css"&gt;
    span.note-mistake {
        color: red;
    }
    span.note-improvement {
        color: orange;
    }
    span.note-question {
        color: green;
    }
    span.note-other {
        color: silver;
    }
&lt;/style&gt;

&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;In summary, &lt;a href="https://www.manning.com/books/netty-in-action"&gt;Netty in Action&lt;/a&gt;
is a book that I would recommend to everyone who wants to learn more about
Netty to use it in their applications. Almost the entire set of fundamental
Netty abstractions are covered in detail. The content is a bliss for novice
users in networking domain. Though this in return might make the book
uninteresting for people who already got their hands pretty dirty with
networking facilities available in Java Platform. That being said, the
presented historical perspective and shared case studies are still pretty
attractive even for the most advanced users.&lt;/p&gt;

&lt;p&gt;I don’t know much about the 2&lt;sup&gt;nd&lt;/sup&gt; author of the book, Marvin Allen
Wolfthal. Though, the 1&lt;sup&gt;st&lt;/sup&gt; author, Norman Maurer, is a pretty known
figure in the F/OSS ecosystem. If he manages to transfer more juice from his
experience and presentations to the book, I will definitely buy the
2&lt;sup&gt;nd&lt;/sup&gt; print of the book too!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2017-04-18://blog/post/2017/10/20/hazelcast-guice/</id>
    <title type="html">Guice Integration in Hazelcast</title>
    <published>2017-04-18T17:22:00Z</published>
    <updated>2017-04-18T17:22:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2017/10/20/hazelcast-guice/"/>
    <content type="html">
&lt;p&gt;For many occassions I find the distributed &lt;code&gt;ExecutorService&lt;/code&gt; of Hazelcast
(aka. &lt;code&gt;IExecutorService&lt;/code&gt;) pretty convenient to turn a set of nodes into a
tamed cluster waiting for orders. You just submit an either &lt;code&gt;Runnable&lt;/code&gt; or
&lt;code&gt;Callable&amp;lt;T&amp;gt;&lt;/code&gt; and Hazelcast takes care of the rest – executing the task on
remote members, acknowledging the response(s) back, etc. Though note that
since the method and its response will be delivered over the wire, it is no
surprise that they all need to be &lt;code&gt;Serializable&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.Hazelcast&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.HazelcastInstance&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.IExecutorService&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.Member&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.MultiExecutionCallback&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.Serializable&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.Map&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.Callable&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.CompletableFuture&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.TimeUnit&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;enum&lt;/span&gt; &lt;span class="n"&gt;HzGuiceDemo&lt;/span&gt; &lt;span class="o"&gt;{;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ProcessorCountTask&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;Serializable&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Callable&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

        &lt;span class="nd"&gt;@Override&lt;/span&gt;
        &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;Integer&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Runtime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getRuntime&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="na"&gt;availableProcessors&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;Throwable&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;HazelcastInstance&lt;/span&gt; &lt;span class="n"&gt;hzInstance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Hazelcast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;newHazelcastInstance&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;IExecutorService&lt;/span&gt; &lt;span class="n"&gt;hzExecutorService&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hzInstance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getExecutorService&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"ballpark"&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;CompletableFuture&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;totalProcessorCountFuture&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;CompletableFuture&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
        &lt;span class="n"&gt;hzExecutorService&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;submitToAllMembers&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;
                &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;ProcessorCountTask&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt;
                &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;MultiExecutionCallback&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

                    &lt;span class="nd"&gt;@Override&lt;/span&gt;
                    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;onResponse&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Member&lt;/span&gt; &lt;span class="n"&gt;member&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                        &lt;span class="c1"&gt;// Ignored.&lt;/span&gt;
                    &lt;span class="o"&gt;}&lt;/span&gt;

                    &lt;span class="nd"&gt;@Override&lt;/span&gt;
                    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;onComplete&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Member&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;totalProcessorCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;
                            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;values&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
                            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
                            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;mapToInt&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;object&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="n"&gt;object&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
                            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sum&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
                        &lt;span class="n"&gt;totalProcessorCountFuture&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;complete&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;totalProcessorCount&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
                    &lt;span class="o"&gt;}&lt;/span&gt;

                &lt;span class="o"&gt;});&lt;/span&gt;
        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;totalProcessorCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;totalProcessorCountFuture&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TimeUnit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;SECONDS&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;format&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"there are %d processors in total%n"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;totalProcessorCount&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;hzInstance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shutdown&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unfortunately many of our tasks are not isolated from the rest of the
application state (i.e., &lt;em&gt;stateless&lt;/em&gt;) as &lt;code&gt;ProcessorCountTask&lt;/code&gt; given above.
Most of the time the functional requirements necessitate access to the remote
node state that is available through beans provided by the underlying
dependency injection framework. Consider the following stateful &lt;code&gt;PizzaService&lt;/code&gt;
that is responsible for cooking pizzas to its users.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;javax.inject.Singleton&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;static&lt;/span&gt; &lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;google&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Preconditions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;checkArgument&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="nd"&gt;@Singleton&lt;/span&gt;
&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PizzaService&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;volatile&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;totalPizzaCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;synchronized&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;cook&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;checkArgument&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;amount&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"expecting: amount &amp;gt; 0, found: %s"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;availablePizzaCount&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;format&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"🍕 cooking %d pizza(s)%n"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We further have a task class to remotely command &lt;code&gt;PizzaService&lt;/code&gt; to cook:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.Serializable&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PizzaCookTask&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;Serializable&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Runnable&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="nd"&gt;@Inject&lt;/span&gt;
    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="n"&gt;PizzaService&lt;/span&gt; &lt;span class="n"&gt;pizzaService&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="nf"&gt;PizzaMakeTask&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;amount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;pizzaService&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;cook&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;amount&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A naive approach to run this task on an &lt;code&gt;IExecutorService&lt;/code&gt; would result in the
following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.Hazelcast&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.HazelcastInstance&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.IExecutorService&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.CompletableFuture&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.TimeUnit&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;enum&lt;/span&gt; &lt;span class="n"&gt;HzGuiceDemo&lt;/span&gt; &lt;span class="o"&gt;{;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;Throwable&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;HazelcastInstance&lt;/span&gt; &lt;span class="n"&gt;hzInstance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Hazelcast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;newHazelcastInstance&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;IExecutorService&lt;/span&gt; &lt;span class="n"&gt;hzExecutorService&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hzInstance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getExecutorService&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"ballpark"&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;hzExecutorService&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;executeOnAllMembers&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;PizzaCookTask&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
        &lt;span class="n"&gt;hzInstance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;shutdown&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which fails with a sweet &lt;code&gt;NullPointerException&lt;/code&gt; as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Exception in thread "main" java.util.concurrent.ExecutionException: java.util.concurrent.ExecutionException: java.lang.NullPointerException
  at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
  at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)
  at com.vlkan.hzguicedemo.HzGuiceDemo.main(HzGuiceDemo.java:??)
Caused by: java.util.concurrent.ExecutionException: java.lang.NullPointerException
  at java.util.concurrent.FutureTask.report(FutureTask.java:122)
  at java.util.concurrent.FutureTask.get(FutureTask.java:192)
  at com.hazelcast.executor.DistributedExecutorService$CallableProcessor.run(DistributedExecutorService.java:189)
  at com.hazelcast.util.executor.CachedExecutorServiceDelegate$Worker.run(CachedExecutorServiceDelegate.java:186)
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
  at java.lang.Thread.run(Thread.java:745)
  at com.hazelcast.util.executor.HazelcastManagedThread.executeRun(HazelcastManagedThread.java:76)
  at com.hazelcast.util.executor.HazelcastManagedThread.run(HazelcastManagedThread.java:92)
Caused by: java.lang.NullPointerException
  at com.vlkan.hzguicedemo.HzGuiceDemo$PizzaCookTask.call(HzGuiceDemo.java:??)
  at com.vlkan.hzguicedemo.HzGuiceDemo$PizzaCookTask.call(HzGuiceDemo.java:??)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What is really happening here is that Hazelcast does not have a magical ball
to guess the dependency injection framework you are using to process the
&lt;code&gt;@Inject&lt;/code&gt;-annotated properties of the &lt;code&gt;PizzaCookTask&lt;/code&gt;. Though Hazelcast has
something else:
&lt;a href="http://docs.hazelcast.org/docs/2.3/manual/html/ch14s02.html"&gt;ManagedContext&lt;/a&gt;.
In a nutshell, &lt;code&gt;ManagedContext&lt;/code&gt; provides means to intercept class
instantiation at deserialization. We can leverage this functionality to come
up with a &lt;code&gt;ManagedContext&lt;/code&gt; implementation that bakes Guice dependency
injection into the Hazelcast class instantiation process.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.google.inject.Injector&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.hazelcast.core.ManagedContext&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;javax.inject.Inject&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;javax.inject.Singleton&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="nd"&gt;@Singleton&lt;/span&gt;
&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;HazelcastGuiceManagedContext&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;ManagedContext&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="n"&gt;Injector&lt;/span&gt; &lt;span class="n"&gt;injector&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="nd"&gt;@Inject&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="nf"&gt;HazelcastGuiceManagedContext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Injector&lt;/span&gt; &lt;span class="n"&gt;injector&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;injector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;injector&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt; &lt;span class="nf"&gt;initialize&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt; &lt;span class="n"&gt;instance&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;injector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;injectMembers&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;instance&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;instance&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next all you need to do is to use this &lt;code&gt;ManagedContext&lt;/code&gt; while creating your
&lt;code&gt;HazelcastInstance&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="n"&gt;Injector&lt;/span&gt; &lt;span class="n"&gt;injector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Guice&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;createInjector&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;HazelcastGuiceManagedContext&lt;/span&gt; &lt;span class="n"&gt;guiceManagedContext&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;injector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getInstance&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;HazelcastGuiceManagedContext&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;Config&lt;/span&gt; &lt;span class="n"&gt;hzConfig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;hzConfig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setManagedContext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;guiceManagedContext&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;HazelcastInstance&lt;/span&gt; &lt;span class="n"&gt;hzInstance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Hazelcast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;newHazelcastInstance&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hzConfig&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While I have provided an example for Guice, this method is applicable to any
dependency injection framework that provides an equivalent to
&lt;code&gt;Injector#injectMembers()&lt;/code&gt; of Guice. Needless to say, but Spring folks are
already covered by &lt;code&gt;SpringManagedContext&lt;/code&gt; shipped with Hazelcast.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2017-04-18://blog/post/2017/04/18/inter-service-comm/</id>
    <title type="html">Inter-Microservice Communication Fatigue</title>
    <published>2017-04-18T17:22:00Z</published>
    <updated>2017-04-18T17:22:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2017/04/18/inter-service-comm/"/>
    <content type="html">
&lt;p&gt;Let me get this straight: &lt;strong&gt;Every single line of code that needs to
communicate with a remote microservice is the most bizarre, annoying, sad, and
hopeless experience in my daily coding routine.&lt;/strong&gt; And the worst is: Most of
the time its &lt;em&gt;my client&lt;/em&gt; code communicating with &lt;em&gt;my services&lt;/em&gt;, so there is no
one else to blame that would sooth my anger. But I did not end up here out of
blue.&lt;/p&gt;

&lt;p&gt;In my freshman years, I was given the responsibility of further development of
a microservice, where both the server and its driver (API models, HTTP client,
etc.) were written in Scala. Because Scala was still a cool buzzword back then
and the team wanted to experiment with it. (No, this won’t be a Scala FUD
post.) It was using an in-house built HTTP client, which is more or less yet
another buggy wrapper over an ancient version of &lt;a href="https://github.com/ning/async-http-client"&gt;Ning
async-http-client&lt;/a&gt;. I implemented a
(yes, another!) thin wrapper over it to expose the HTTP response models as
&lt;code&gt;scala.concurrent.Future&lt;/code&gt;s, so we can compose them via Scala’s
for-comprehensions. (It did not take long for me to figure out that exposing
the API in Scala was one of the worst possible design decisions one could have
made in an ecosystem dominated by Java consumers.)&lt;/p&gt;

&lt;p&gt;Later on as a team we adopted another critical microservice comprising a giant
Java client with Spring fizz and buzz, caching, Guava immutables all under the
hood with insanely strict &lt;code&gt;checkNotNull&lt;/code&gt;/&lt;code&gt;checkArgument&lt;/code&gt;-powered model
validation, etc. This comet created its own fan clubs. There are two types of
people in the company who are consuming this service:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;ones that bite the bullet and use the gigantic driver we
provide (say hello to a truck load of artifacts in your
not-sufficiently-sucking dependency hell) or&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ones that prefer to implement his/her own HTTP driver hosting an empire of
bugs by manually building/parsing query request/response models formatted
in JSON/XML/Protobuf.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Later on I said enough is enough! Let’s stick to a standard: JEE HTTP client,
that is, Jersey JAX-RS Client with Jackson cream on it. I still needed to
create all the API models and verify them myself every time. It was bearable
to some extent. But here comes the perfect storm: JAX-RS Client 2.0 (which
supports proper HTTP connection pooling with sanely configurable
socket+connection timeout support, which weren’t sanely available in 1.x)
requires &lt;code&gt;javax.ws.rs-api&lt;/code&gt; 2.x, which is binary incompatible with 1.x, which
is used by 80% of microservices in the ecosystem. So in practice no other
microservice will be able to use my driver without the developer losing half
of his/her hairs.&lt;/p&gt;

&lt;p&gt;Later on I kept repeating “enough is enough”! Let’s use &lt;a href="https://github.com/AsyncHttpClient/async-http-client"&gt;Google’s
async-http-client&lt;/a&gt;. It
is pluggable all around the place: the HTTP connector (Apache HC, etc.),
marshaller (Jackson, Gson, etc.). The project is more or less undocumented.
But thanks to an army of Android users, there is plenty of blog posts and
source code to discover your own personal bugs, so you can keep on blog
posting about it. Anyway… It worked. I still need to motivate myself to dive
into the source code to comprehend how it works under the hood, but it worked.&lt;/p&gt;

&lt;p&gt;Today… When I need to talk to one of these services I need to pick a lousy,
juice, smelly sh*t of my preference:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Inject the entire Scala milky way into your 1-file Java microservice, which
could have been delivered as a 5MB fat-JAR before Scala space-warping it
into 50MB. And don’t forget to pat your IDE in the back every time it needs
to auto-complete a Scala class. Oh, by the way, have you ever tried
accessing a &lt;code&gt;scala.Option&lt;/code&gt; from Java? Boy! It is fun! I hope your service
consumers think likewise.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Let the giant Java driver bring all its feature-rich functionality together
with its cousins, its nephews, its uncle, its grandma, its grandpa, its
friends from the school, its ex, and of course with spring-core. All you
wanted is to make a &lt;code&gt;GET&lt;/code&gt; to &lt;code&gt;/v1/user/&amp;lt;id&amp;gt;&lt;/code&gt;, but now you have the entire
Pivotal art gallery decorating your &lt;code&gt;mvn dependency:tree&lt;/code&gt; output on the
wall.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You can of course purpose maven-shade-plugin to shade and relocate the
entire &lt;code&gt;javax.ws.rs-api&lt;/code&gt;, Jersey dependencies, together with the entire
universe. I know you can do that.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Browse to Google’s &lt;code&gt;async-http-client&lt;/code&gt; webpage and try to find the page that
explains how to make a simple fscking &lt;code&gt;GET&lt;/code&gt; request.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Embrace the old Ning client wrapper, welcome bugs (the first time I needed
to use it I found out that &lt;code&gt;setHeaders()&lt;/code&gt; wasn’t working as expected), stick
to JAX-RS 1.x and an ancient Netty version, which causes a JAR Hell with any
recent library, e.g., Elasticsearch. (Please refer back to
maven-shade-plugin item.)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I can hear you shouting about compile-time generated HTTP clients based on
Swagger or WADL specs. But weren’t we just cursing WSDL and trying to run away
from it? &lt;a href="square.github.io/retrofit/"&gt;Retrofit&lt;/a&gt;?
&lt;a href="https://twitter.github.io/finagle/"&gt;Finagle&lt;/a&gt;? &lt;a href="http://www.grpc.io/"&gt;gRPC&lt;/a&gt;? I
bet it is a matter of time until you end up needing to consume two clients
which have transitive dependencies to two binary incompatible versions of
Retrofit/Finagle/gRPC. You can blame the Java class loader mechanism. But that
doesn’t make the problem fade away. Oh! I was just about to forget! Wait until
I migrate to &lt;code&gt;rx.Completable&lt;/code&gt; from &lt;code&gt;rx.Single&amp;lt;Void&amp;gt;&lt;/code&gt;, which I migrated from
&lt;code&gt;rx.Observable&amp;lt;Void&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I am exhausted and demotiviated to write yet another single line of code that
needs to communicate with a remote microservice and which could have been a
simple fucking RPC. I don’t have a solution for the mud ball in my hands. Even
if I do have, I am not sure whether it will survive a couple of years or not.
But in the back of my head, I keep on cursing the Java Platform SE guys: How
difficult could it be to come up with a proper pluggable HTTP client? Compared
to &lt;code&gt;NPE&lt;/code&gt;, Java’s HTTP client is not &lt;em&gt;the&lt;/em&gt; billion dollar mistake, but a really
close one.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2016-10-04://blog/post/2016/10/04/coders-at-work/</id>
    <title type="html">Notes on "Coders at Work"</title>
    <published>2016-10-04T18:40:00Z</published>
    <updated>2016-10-04T18:40:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2016/10/04/coders-at-work/"/>
    <content type="html">
&lt;p&gt;There is nothing like thinking about work while your are on vacation. And that
was indeed what I did: Reading &lt;a href="http://www.codersatwork.com/"&gt;Coders at Work: Reflections on the Craft of
Programming&lt;/a&gt; in a tango-themed Buenos Aires
trip.&lt;/p&gt;

&lt;p&gt;I had already met with Peter Seibel in his well-known splendid work:
&lt;a href="http://www.gigamonkeys.com/book/"&gt;Practical Common Lisp&lt;/a&gt;. He definitely has a
knack for transforming technically challenging problems into a pedagogically
digestable &lt;a href="https://en.wikipedia.org/wiki/Nootropic"&gt;nootropic&lt;/a&gt;. This uncanny
ability was placidly lurid in Coders at Work as well. Motivated by the mind
provoking exquisite content, I felt an urge to keep a record of its
reflections on me.&lt;/p&gt;

&lt;h1 id="on-the-content"&gt;On the Content&lt;/h1&gt;

&lt;p&gt;I totally enjoyed the book and read it cover to cover. Nevertheless, I believe
the following subtleties could have been addressed in a better way.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A majority of the interviewed &lt;em&gt;coders&lt;/em&gt; are not actively &lt;em&gt;coding&lt;/em&gt; any more. I
find this a little bit contradictory with the title of the book. While the
content still makes a great deal about the historical progress of
programming and programmers, I find the detachment of the interviewees from
the modern computing slightly unexpected.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Given the back that the book examines the events dating back to more than
half a century, I sometimes find myself lost in the time context. Additional
footnotes to enhance these kind of ambiguities could have been useful.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id="highligts"&gt;Highligts&lt;/h1&gt;

&lt;p&gt;Below I collected my personal highligts on certain statements that are shared
by certain interviewees.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In general, &lt;em&gt;coders&lt;/em&gt; do not practice software testing extensively. Further,
I had the impression that that they do not read much programming books
either. This issue sometimes acclaimed to the lack of necessary set of
fundamental books at the early stages of their career.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Among the entire deck, I find Joshua Bloch, Bernie Cosell, and Donald Knuth
the ones with the most sensible and to-the-earth statements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A notable subset of the interviewees dragged into computers not by a
deliberate decision, but by chosing a yet another career path that was
available to them. (For instance, Fran Allen got a Fortran instructor
position in IBM in order to finance her school loans to be able to continue
her math teacher career pursuit.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;None believes that reading Knuth’s &lt;a href="https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming"&gt;The Art of Computer
Programming&lt;/a&gt;
is a must read for programmers, nevertheless they acknowledge that it is
good to have it under your hand for reference.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Except Knuth himself, nobody practices literate programming. (I am astounded
to observe how Seibel is biased to ask this non-sense question which
delivers no practical value at all to every single candidate.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Majority agrees that programming is a way more complicated and challenging
occupation than it once used to be in the past.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;More than half thinks that good writing skills are a big plus (some even
state necessity) for programming.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;printf&lt;/code&gt; is the clear winner as the debugging tool of preference among
interviewees.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id="quotes"&gt;Quotes&lt;/h1&gt;

&lt;p&gt;Below you can find some snippets that I find worth mentioning from the book.&lt;/p&gt;

&lt;h2 id="jamie-zawinski"&gt;Jamie Zawinski&lt;/h2&gt;

&lt;p&gt;I wish I would have known this when I was in high school. Could not agree
more.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Zawinski:&lt;/strong&gt; When you’re in high school, everyone tells you, “There’s a lot
of repetitive bullshit and standardized tests; it’ll all be better once
you’re in college.” And then you get to your first year of college and
they’re like, “Oh, no – it gets better when you’re in grad school.” So it’s
just same shit, different day – I couldn’t take it. [p5]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;His comments on C++, which are shared by many other interviewees throughout
the book:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Zawinski:&lt;/strong&gt; … when you’re programming C++ no one can ever agree on which
ten percent of the language is safe to use. [p20]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The sad truth about F/OSS:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; Isn’t it exactly this thing – someone comes along and says, “I
can’t understand this stuff. I’ll just rewrite it” – that leads to the
endless rewriting you bemoan in open-source development?&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Zawinski:&lt;/strong&gt; Yeah. But there’s also another aspect of that which is,
efficiency aside, it’s just more fun to write your own code than to figure
out someone else’s. So it is easy to understand why that happens. But the
whole Linux/GNOME side of things is straddling this line between someone’s
hobby and a product. Is this a research project where we’re deciding what
desktops should look like and we’re experimenting? Or are we competing with
Macintosh? Which is it? Hard to do both. [p23]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="brad-fitzpatrick"&gt;Brad Fitzpatrick&lt;/h2&gt;

&lt;p&gt;His thoughts on finishing a project, which I sadly share as well:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Fitzpatrick:&lt;/strong&gt; The projects that I never finish … it’s because I did the
hard part and I learned what I wanted to learn and I never got around to
doing the boring stuff. [p20]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;He is also poisoned by LWN, Reddit, etc.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Fitzpatrick:&lt;/strong&gt; I like working alone but I just bounce all over the place
when I do. On a plane I’ll bring extra laptop batteries and I have a whole
development environment with local web servers and I’ll be in a web browser,
testing stuff. But I’ll still be hitting new tabs, and typing “reddit” or
“lwn” – sites I read. Autocomplete and hit Enter, and then – error
message. I’ll do this multiple times within a minute. Holy fuck! Do I do
this at work? Am I reading web site this often that I don’t even think about
it? It’s scary. I had a friend, who had some iptables rule, that on
connection to a certain IP address between certain hours of the day would
redirect to a “You should be working” page. I haven’t got around to doing
that, but I need to do something like it, probably. [p73]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="douglas-crockford"&gt;Douglas Crockford&lt;/h2&gt;

&lt;p&gt;Why programming is difficult?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Crockford:&lt;/strong&gt; Part of what makes programming difficult is most of the time
we’re doing stuff we’ve never done before. [p110]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;He talks about his preferred way for interviewing job candidates, which is also
shared by other coders in the book.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Crockford:&lt;/strong&gt; The approach I’ve taken now is to do a code reading. I invite
the candidate to bring in a piece of code he’s really proud of and walk us
through it. [p129]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="brendan-eich"&gt;Brendan Eich&lt;/h2&gt;

&lt;p&gt;Nothing noteworthy, you may guess why.&lt;/p&gt;

&lt;h2 id="joshua-bloch"&gt;Joshua Bloch&lt;/h2&gt;

&lt;p&gt;Is Java off in the weeds?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; … is Java off in the weeds a little bit? Is it getting more
complex faster than it’s getting better?&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Bloch:&lt;/strong&gt; That’s a very difficult question. In particular, the Java 5
changes added far more complexity than we ever intended. I had no
understanding of just how much complexity generics and, in particular,
wildcards were going to add to the language. I have to give credit where is
due – Graham Hamilton did understand this at the time and I didn’t.&lt;/p&gt;

  &lt;p&gt;The funny things is, he fought against it for years, trying to keep generics
out of the language. But the notion of variance – the idea behind wildcards
– came into fashion during the years when generics were successfully being
kept out of Java. If they had gone in earlier, without variance, we might
have had a simpler, more tractable language today.&lt;/p&gt;

  &lt;p&gt;That said, there are real benefits to wildcards. There’s a fundamental
impedance mismatch between subtyping and generics, and wildcards go a long
way towards rectifying the mismatch. But at a significant cost in terms of
complexity. THere are some people who believe that declaration-site, as
opposed to use-site, variance is a better solution, but I’m not so sure.&lt;/p&gt;

  &lt;p&gt;The jury is basically still out on anything that hasn’t been tested by a
huge quantity of programmers under real-world conditions. Often languages
only succeed in some niche and people say, “Oh, they’re great and it’s such
a pity they didn’t become the successful language in the world.” But often
there are reasons they didn’t. Hopefully some language that does use
declaration-site variance, like Scala or C# 4.0, will answer this question
once and for all. [p191]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On “obviously no deficiencies” versus “no obvious deficiencies”:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Bloch:&lt;/strong&gt; There’s a brilliant quote by Tony Hoare in his Turing Award
speech about how there are two ways to design a system: “One way is to make
it so simple that there are &lt;em&gt;obviously&lt;/em&gt; no deficiencies and the other way is
to make it is so complicated that there are no &lt;em&gt;obvious&lt;/em&gt; deficiencies.”&lt;/p&gt;

  &lt;p&gt;The paragraph that follows is equally brilliant, though it isn’t as
well-known: “The first method is far more difficult. It demands the same
skill, devotion, insight, and even inspiration as the discovery of the
simple physical laws which underlie the complex phenomena of nature. It also
requires a willingness to accept objectives which are limited by physical,
logical, and technological constraints, and to accept a compromise when
conflicting objectives cannot be met. No committee will ever do this until
it is too late.” [p197]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Smart people and programming:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; Speaking of writing intricate code, I’ve noticed that people who
are too smart, in a certain dimension anyway, make the worst code. Because
they can actually fit the whole thing in their head they can write these
great reams of spaghetti code.&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Bloch:&lt;/strong&gt; I agree with you that people who are both smart enough to cope
with enormous complexity and lack empathy with the rest of use may fail prey
to that. They think, “I can understand this and I can use it, so it has to
be good.” [p202]&lt;/p&gt;

  &lt;p&gt;…&lt;/p&gt;

  &lt;p&gt;There’s this problem, which is, programming is so much of an intellectual
meritocracy and often these people are the smartest people in the
organization; therefore they figure they should be allowed to make all the
decisions. But merely the fact that they’re the smartest people in the
organization doesn’t mean they should be making all the decisions, because
intelligence is not a scalar quantity; it’s a vector quantity. And if you
lack empathy or emotional intelligence, then you shouldn’t be designing APIs
or GUIs or languages. [p203]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="joe-armstrong"&gt;Joe Armstrong&lt;/h2&gt;

&lt;p&gt;On paralyses of choice:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Armstrong:&lt;/strong&gt; The funny thing is, thinking back, I don’t think all these
modern gizmos actually make you any more productive. Hierarchical file
systems – how do they make you more productive? Most of software
development goes on in your head anyway. I think having worked with that
simpler system imposes a kind of disciplined way of thinking. If you haven’t
got a directory system and you have to put all the files in one directory,
you have to be fairly disciplined. If you haven’t got a revision control
system, you have to be fairly disciplined. Given that you apply that
discipline to what you’re doing it doesn’t seem to me to be any better to
have hierarchical file systems and revision control. They don’t solve the
fundamental problem of solving your problem. They probably make it easier
for groups of people to work together. For individuals I don’t see any
difference.&lt;/p&gt;

  &lt;p&gt;Also, I think today we’re kind of overburdened by choice. I mean, I just had
Fortran. I don’t think we even had shell scripts. We just had batch files so
you could run things, a compiler, and Fortran. And assembler possibly, if
you really needed it. So there wasn’t this agony of choice. Being a young
programmer today must be awful – you can choose 20 different programming
languages, dozens of framework and operating systemsand you’re paralyzed by
choice. There was no paralysis of choice then. You just start doing it
because the decision as to which language and things is just made – there’s
no thinking about what you should do, you just go and do it. [p210]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="simon-peyton-jones"&gt;Simon Peyton Jones&lt;/h2&gt;

&lt;p&gt;Testing an API in Microsoft:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Peyton Jones:&lt;/strong&gt; Well, they also do some interesting work on testing APIs.
Steven Clarke and his colleagues at Redmond have made systematic attempts to
watch programmers, given a new API, talk through what they’re trying to do.
And they get the people who designed the API to sit behind a glass screen
and watch them.&lt;/p&gt;

  &lt;p&gt;And the guys sitting there behind the glass screen say, “No, no, don’t do
that! That’s not the right way!” But it’s soundproof. That turns out often
to be very instructive. They go and change their API. [p253]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="peter-norvig"&gt;Peter Norvig&lt;/h2&gt;

&lt;p&gt;On the traditional master and apprentice approach:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Norvig:&lt;/strong&gt; But I think part of the reasons why you had master and
apprentice is because the materials were rarer. When you were doing
goldsmithing, there’s only so much gold. Or when the surgeon’s operating,
there’s only one heart, and so you want the best person on that and you want
the other guys just helping. With coding, it’s not like that. You’ve got
plenty of terminals. You’ve got plenty of keyboards. You don’t have to
ration it. [p295]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Why programming is not an art, but a craft:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; As a programmer, do you consider yourself a scientist, an
engineer, an artist, or a craftsman?&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Norvig:&lt;/strong&gt; Well, I know when you compare the various titles of books and so
on, I always thought the “craft” was the right answer. So I thought art was
a little pretentious because the purpose of art is to be beautiful or to
have an emotional contact or emotional impact, and I don’t feel like that’s
anything that I try to do. Certainly I want programs to be pretty in some
ways, and sometimes I feel like I spend too much time doing that. I’ve been
in a position where I’ve had the luxury to say, “Gee, I have time to go back
and pretty this up a little bit.” And places where I’ve been able to write
for a publication, you spend more time doing that than you would if it was
just for your own professional growth.&lt;/p&gt;

  &lt;p&gt;But I don’t think of that as art. I think &lt;em&gt;craft&lt;/em&gt; is really the right word
for it. You can make a chair, and it’s good looking, but it’s mostly
functional – it’s a chair. [p319]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="guy-steele"&gt;Guy Steele&lt;/h2&gt;

&lt;p&gt;On the difficulty of getting a program right:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Steele:&lt;/strong&gt; I’ll give you another example – suppose I were to tell my smart
computer, “OK, I’ve got this address book and I want the addresses to always
be in sorted order,” and it responds by throwing away everything but the
first entry. Now the address book is sorted. But that’s not what you wanted.
It turns out that just specifying something as simple as “a list is in
sorted order and I haven’t lost any of the data and nothing has been
duplicated” is actually a fairly tricky specification to write. [p361]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="dan-ingalls"&gt;Dan Ingalls&lt;/h2&gt;

&lt;p&gt;Was a nice read, though I could not find anything particularly interesting
worth sharing. Nevertheless, along the lines Seibel says something that I have
never heard of:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; Alan Kay has said that both Lisp and Smalltalk have the problem
that they’re so good they eat their children. If you had known Lisp, then
Smalltalk would have been the first eaten child. [p378]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="l-peter-deutsch"&gt;L Peter Deutsch&lt;/h2&gt;

&lt;p&gt;On getting data structures right:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Deutsch:&lt;/strong&gt; … if you get the data structures and their invariants right,
most of the code will just kind of write itself. [p420]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Conceptualization of software and memory pointers:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Deutsch:&lt;/strong&gt; … I don’t look around and see anything that looks like an
address or a pointer. We have objects; we don’t have these weird things that
computer scientists misname “objects.”&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; To say nothing of the scale. Two to the 64th of anything is a
lot, and things happening billions of times a second is fast.&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Deutsch:&lt;/strong&gt; But that doesn’t bother us here in the real world. You know
Avogadro’s number, right? Ten to the 23rd? So, we’re looking here around at
a world that has incredible numbers of little things all clumped together
and happening at the same time. It doesn’t bother us because the world is
such that you don’t have to understand this table at a subatomic level. The
physical properties of matter are such that 99.9 percent of the time you can
understand it in aggregate. And everything you have to know about it, you
can understand from dealing with it in aggregate. To a great extent, that is
not true in the world of software.&lt;/p&gt;

  &lt;p&gt;People keep trying to do modularization structures for software. And the
state of that art has been improving over time, but it’s still, in my
opinion, very far away from the ease with which we look around and see
things that have, whatever it is, 10 to the 23rd atoms in them, and it
doesn’t even faze us.&lt;/p&gt;

  &lt;p&gt;Software is a discipline of detail, and that is a deep, horrendous
fundamental problem with software. Until we understand how to conceptualize
and organize software in a way that we don’t have to think about how every
little piece interacts with every other piece, things are not going to get a
whole lot better. And we’re very far from being there. [p424]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="ken-thompson"&gt;Ken Thompson&lt;/h2&gt;

&lt;p&gt;On teaching:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; … I love the teaching: the hard work of a first class, the
fun of the second class. Then the misery of the third. [p455]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What I am supposed to do and what I am actually doing:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; We were supposed to be doing basic research but there was some
basic research we should be doing and some basic research we shouldn’t be
doing. And just coming out of the ashes of MULTICS, operating systems was
one of those basic research things we shouldn’t be doing. Because we tried
it, it didn’t work, it was a huge failure, it was expensive; let’s drop it.
So I kind of expected that for what I was doing I was going to eventually
get fired. I didn’t. [p458]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Code rots:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; Code by itself almost rots and it’s gotta be rewritten. Even
when nothing has changed, for some reason it rots. [p460]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;10 percent of the work:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; NELIAC was a system-programming version of Algol 58.&lt;/p&gt;

  &lt;p&gt;Seibel: Was Bliss also from that era?&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; Bliss I think was after. And their emphasis was trying to
compile well. I think it was pretty clear from the beginning that you
shouldn’t kill yourself compiling well. You should do well but not really
good. And the reason is that in the time it takes you to go from well to
really good, Moore’s law has already surpassed you. You can pick up 10
percent but while you’re picking up that 10 percent, computers have gotten
twice as fast and maybe with some other stuff that matters more for
optimization, like caches. I think it’s largely a waste of time to do really
well. It’s really hard; you generate as many bugs as you fix. You should
stop, not take that extra 100 percent of time to do 10 percent of the work.
[p462]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Writing an OS to test a file system:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; So you basically wrote an OS so you’d have a better environment
to test your file system.&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; Yes. Halfway through there that I realized it was a real time-
sharing system. I was writing the shell to drive the file system. And then I
was writing a couple other programs that drove the file system. And right
about there I said, “All I need is an editor and I’ve got an operating
system.” [p465]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Economics of deciding on introducing a bag:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; Certainly every time I’ve written one of these non-compare
subroutine calls, strcpy and stuff like that, I know that I’m writing a bug.
And I somehow take the economic decision of whether the bug is worth the
extra arguments. [p468]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On testing:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; … Mostly just
regression tests.&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; By things that are harder to test, you mean things like device
drivers or networking protocols?&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; Well, they’re run all the time when you’re actually running an
operating system.&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; So you figure you’ll shake the bugs out that way?&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; Oh, absolutely. I mean, what’s better as a test of an
operating system than people beating on it? [p469]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Code at Google:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; I guess way more than 50 percent of the code is the what-if
kind. [p473]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On literate programming:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Seibel:&lt;/strong&gt; When I interviewed him, Knuth said the key to technical writing
is to say everything twice in complementary ways. So I think he sees that as
a feature of literate programming, not a bug.&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Thompson:&lt;/strong&gt; Well if you have two ways, one of them is real: what the
machine executes. [p477]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="fran-allen"&gt;Fran Allen&lt;/h2&gt;

&lt;p&gt;What makes a program beautiful?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Allen:&lt;/strong&gt; That it is a simple straightforward solution to a problem; that
has some intrinsic structure and obviousness about it that isn’t obvious
from the problem itself. [p489]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="bernie-cosell"&gt;Bernie Cosell&lt;/h2&gt;

&lt;p&gt;Should we teach Knuth to students?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cosell:&lt;/strong&gt; I would not teach students Knuth per se for two reasons. First,
it’s got all this mathematical stuff where he’s not just trying to present
the algorithms but to derive whether they’re good or bad. I’m not sure you
need that. I understand a little bit of it and I’m not sure I need any of
it. But getting a feel for what’s fast and what’s slow and when, that’s an
important thing to do even if you don’t know how much faster or how much
slower.&lt;/p&gt;

  &lt;p&gt;The second problem is once students get sensitive to that, they get too
clever by half. They start optimizing little parts of the program because,
“This is the ideal place to do an AB unbalanced 2-3 double reverse backward
pointer cube thing and I always wanted to write one of those.” So they spend
a week or two tuning an obscure part of a program that doesn’t need
anything, which is now more complicated and didn’t make the program any
better. So they need a tempered understanding that there are all these
algorithms, how they work, and how to apply them. It’s really more of a case
of how to pick the right one for the job you’re trying to do as opposed to
knowing that this one is an order n-cubed plus three and this one is just
order n-squared times four. [p527]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Writing programs and learning how to program:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cosell:&lt;/strong&gt; The binary bits are what computers want and the text file is for
me. I would get people – bright, really good people, right out of college,
tops of their classes – on one of my projects. And they would know all
about programming and I would give them some piece of the project to work
on. And we would start crossing swords at our project-review meetings. They
would say, “Why are you complaining about the fact that I have my global
variables here, that I’m not doing this, that you don’t like the way the
subroutines are laid out? The program works.”&lt;/p&gt;

  &lt;p&gt;They’d be stunned when I tell them, “I don’t care that the program works.
The fact that you’re working here at all means that I expect you to be able
to write programs that work. Writing programs that work is a skilled craft
and you’re good at it. Now, you have to learn how to program.” [p543]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Convictions:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cosell:&lt;/strong&gt; I had two convictions, which actually served me well: that
programs ought to make sense and there are very, very few inherently hard
problems. [p549]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;How long is it going to take you to put this change in?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cosell:&lt;/strong&gt; So when they ask, “How long is it going to take you to put this
change in?” you have three answers. The first is the absolute shortest way,
changing the one line of code. The second answer is how long it would be
using my simple rule of rewriting the subroutine as if you were not going to
make that mistake. Then the third answer is how long if you fix that bug if
you were actually writing this subroutine in the better version of the
program. [p550]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Artistry in programming:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cosell:&lt;/strong&gt; Part of what I call the artistry of the computer program is how
easy it is for future people to be able to change it without breaking it.
[p555]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Difficulty of programming and C:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cosell:&lt;/strong&gt; … programmers just can’t be careful enough. They don’t see all
the places. And C makes too many places. Too scary for me, and I guess it’s
fair to say I’ve programmed C only about five years less than Ken has. We’re
not in the same league, but I have a long track record with C and know how
difficult it is and I think C is a big part of the problem. [p559]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;75 million run-of-the-mill programmers and Java:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cosell:&lt;/strong&gt; When I first messed with Java – this was when it was little
baby language, of course – I said, “Oh, this is just another one of those
languages to help not-so-good programmers go down the straight and narrow by
restricting what they can do.” But maybe we’ve come to a point where that’s
the right thing. Maybe the world has gotten so dangerous you can’t have a
good, flexible language that one percent or two percent of the programmers
will use to make great art because the world is now populated with 75
million run-of-the-mill programmers building these incredibly complicated
applications and they need more help than that. So maybe Java’s the right
thing. I don’t know. [p560]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Not-so-good programmers and C:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cosell:&lt;/strong&gt; I don’t want to say that C has outlived its usefulness, but I
think it was used by too many good programmers so that now not-good-enough
programmers are using it to build applications and the bottom line is
they’re not good enough and they can’t. Maybe C is the perfect language for
really good systems programmers, but unfortunately not-so-good systems and
applications programmers are using it and they shouldn’t be. [p560]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id="donald-knuth"&gt;Donald Knuth&lt;/h2&gt;

&lt;p&gt;Teaching a class, writing a book, and programming:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Knuth:&lt;/strong&gt; I could teach classes full-time and write a book full-time but
software required so much attention to detail. It filled that much of my
brain to the exclusion of other stuff. So it gave me a special admiration
for people who do large software projects – I would never have guessed it
without having been faced with that myself. [p572]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Why isn’t everybody a super programmer and super writer?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Knuth:&lt;/strong&gt; Now, why hasn’t this spread over the whole world and why isn’t
everybody doing it? I’m not sure who it was who hit the nail on the head –
I think it was Jon Bentley. Simplified it is like this: only two percent of
the world’s population is born to be super programmers. And only two percent
of the population is born to be super writers. And Knuth is expecting
everybody to be both. [p574]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Use of pointers in C:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Knuth:&lt;/strong&gt; To me one of the most important revolutions in programming
languages was the use of pointers in the C language. When you have
nontrivial data structures, you often need one part of the structure to
point to another part, and people played around with different ways to put
that into a higher- level language. Tony Hoare, for example, had a pretty
nice clean system but the thing that the C language added – which at first
I thought was a big mistake and then it turned out I loved it – was that
when x is a pointer and then you say, x + 1 , that doesn’t mean one more
byte after x but it means one more node after x , depending on what x points
to: if it points to a big node, x
+ 1 jumps by a large amount; if x points to a small thing, x + 1 just moves
a little. That, to me, is one of the most amazing improvements in notation.
[p585]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I did not know about Knuth’s &lt;em&gt;change files&lt;/em&gt;. But it seemed like an
inconvenient overkill:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Knuth:&lt;/strong&gt; I had written TeX and Metafont and people started asking for it.
And they had 200 or 300 combinations of programming language and operating
system and computer, so I wanted to make it easy to adapt my code to
anybody’s system. So we came up with the solution that I would write a
master program that worked at Stanford and then there was this add-on called
a change file which could customize it to anybody else’s machine.&lt;/p&gt;

  &lt;p&gt;A change file is a very simple thing. It consists of a bunch of little blobs
of changes. Each change starts out with a few lines of code. You match until
you find the first line in the master file that agrees with the first line
of your change. When you get to the end of the part of the change that was
supposed to match the master file, then comes the part which says, “Replace
that by these lines instead.” [p586]&lt;/p&gt;

  &lt;p&gt;The extreme example of this was when TeX was adapted to Unicode. They had a
change file maybe 10 times as long as the master program. In other words,
they changed from an 8-bit program to a 16-bit program but instead of going
through and redoing my master program, they were so into change files that
they just wrote their whole draft of what they called Omega as change files,
as a million lines of change files to TeX’s 20,000 lines of code or
something. So that’s the extreme. [p587]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Is programming fun any more?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Knuth:&lt;/strong&gt; So there’s that change and then there’s the change that I’m
really worried about: that the way a lot of programming goes today isn’t any
fun because it’s just plugging in magic incantations – combine somebody
else’s software and start it up. It doesn’t have much creativity. I’m
worried that it’s becoming too boring because you don’t have a chance to do
anything much new. [p594]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Code reading:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Knuth:&lt;/strong&gt; … don’t only read the people who code like you. [p601]&lt;/p&gt;
&lt;/blockquote&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2016-08-12://blog/post/2016/08/12/hotspot-heapdump-threadump/</id>
    <title type="html">Programmatically Taking Heap and Thread Dumps in HotSpot</title>
    <published>2016-08-12T17:53:00Z</published>
    <updated>2016-08-12T17:53:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2016/08/12/hotspot-heapdump-threadump/"/>
    <content type="html">
&lt;p&gt;While taking heap and thread dumps are one click away using modern JVM
toolset, in many cases the deployment environment access restrictions render
these options unusable. Hence, you might end up exposing these functionalities
in certain ways like an internal REST interface. This implies a new nasty
obstacle: You need to know how to programmatically take heap and thread dumps
in a Java application. Unfortunately, there does not exist a standard
interface to access these functionalities within the VM as of date. But if you
are only concerned about HotSpot, then you are in luck!&lt;/p&gt;

&lt;h1 id="heap-dumps"&gt;Heap Dumps&lt;/h1&gt;

&lt;p&gt;For heap dumps, once you get your teeth into a
&lt;a href="https://docs.oracle.com/javase/8/docs/jre/api/management/extension/com/sun/management/HotSpotDiagnosticMXBean.html"&gt;HotSpotDiagnosticMXBean&lt;/a&gt;,
you are safe to go. It already exposes a
&lt;a href="https://docs.oracle.com/javase/8/docs/jre/api/management/extension/com/sun/management/HotSpotDiagnosticMXBean.html#dumpHeap-java.lang.String-boolean-"&gt;dumpHeap()&lt;/a&gt;
method ready to be used.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.sun.management.HotSpotDiagnosticMXBean&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;javax.management.MBeanServer&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.File&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.IOException&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.lang.management.ManagementFactory&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;enum&lt;/span&gt; &lt;span class="n"&gt;HotSpotHeapDumps&lt;/span&gt; &lt;span class="o"&gt;{;&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="n"&gt;HotSpotDiagnosticMXBean&lt;/span&gt; &lt;span class="n"&gt;HOT_SPOT_DIAGNOSTIC_MX_BEAN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
            &lt;span class="n"&gt;getHotspotDiagnosticMxBean&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;HotSpotDiagnosticMXBean&lt;/span&gt; &lt;span class="nf"&gt;getHotspotDiagnosticMxBean&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;MBeanServer&lt;/span&gt; &lt;span class="n"&gt;server&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ManagementFactory&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getPlatformMBeanServer&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ManagementFactory&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;newPlatformMXBeanProxy&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;server&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;HOT_SPOT_DIAGNOSTIC_MX_BEAN_NAME&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;HotSpotDiagnosticMXBean&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;RuntimeException&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"failed getting Hotspot Diagnostic MX bean"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;create&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;boolean&lt;/span&gt; &lt;span class="n"&gt;live&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;HOT_SPOT_DIAGNOSTIC_MX_BEAN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;dumpHeap&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getAbsolutePath&lt;/span&gt;&lt;span class="o"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;live&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The second argument of &lt;code&gt;dumpHeap&lt;/code&gt; denotes live objects, that is, objects that
are reachable from others.&lt;/p&gt;

&lt;p&gt;Note that many real-world Java applications occupy quite some memory. As a
result of this, created heap dump generally end up consuming significant
amount of disk space. You need to come up with your own custom clean up
mechanism to tackle this problem. (For instance, in a JAX-RS resource, you can
purpose a custom &lt;code&gt;MessageBodyWriter&lt;/code&gt; to delete the file after writing the
entire file to the output stream.)&lt;/p&gt;

&lt;h1 id="thread-dumps"&gt;Thread Dumps&lt;/h1&gt;

&lt;p&gt;When you think first about thread dumps, they just contain simple plain text
data.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016-08-12 18:40:46
Full thread dump OpenJDK 64-Bit Server VM (25.76-b198 mixed mode):

"RMI TCP Connection(266)-127.0.0.1" #24884 daemon prio=9 os_prio=0 tid=0x00007f9474010000 nid=0x2cee runnable [0x00007f941571b000]
   java.lang.Thread.State: RUNNABLE
    at java.net.SocketInputStream.socketRead0(Native Method)
    at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
    at java.net.SocketInputStream.read(SocketInputStream.java:170)
    at java.net.SocketInputStream.read(SocketInputStream.java:141)
    at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
    at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
    - locked &amp;lt;0x00000005c086e8b0&amp;gt; (a java.io.BufferedInputStream)
    at java.io.FilterInputStream.read(FilterInputStream.java:83)
    at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:550)
    at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826)
    at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:683)
    at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler$$Lambda$83/628845041.run(Unknown Source)
    at java.security.AccessController.doPrivileged(Native Method)
    at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)

   Locked ownable synchronizers:
    - &amp;lt;0x00000005c0489198&amp;gt; (a java.util.concurrent.ThreadPoolExecutor$Worker)

"JobScheduler FJ pool 0/4" #24883 daemon prio=6 os_prio=0 tid=0x00007f946415d800 nid=0x2ced waiting on condition [0x00007f94093d2000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at sun.misc.Unsafe.park(Native Method)
    - parking to wait for  &amp;lt;0x00000005d8a5f9e0&amp;gt; (a jsr166e.ForkJoinPool)
    at jsr166e.ForkJoinPool.awaitWork(ForkJoinPool.java:1756)
    at jsr166e.ForkJoinPool.scan(ForkJoinPool.java:1694)
    at jsr166e.ForkJoinPool.runWorker(ForkJoinPool.java:1642)
    at jsr166e.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:108)

   Locked ownable synchronizers:
    - None
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unfortunately, thread dumps do not have a standard syntax. While there are
various ways to produce this output, thread dump analysis software does not
play well with them. For instance, &lt;a href="https://www.ibm.com/developerworks/community/groups/service/html/communityview?communityUuid=2245aa39-fa5c-4475-b891-14c205f7333c"&gt;IBM Thread and Monitor Dump Analyzer for
Java&lt;/a&gt;
cannot parse thread dumps created by VisualVM using JMX. At the end of the
day, I always needed to fall back to a HotSpot thread dump.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tools.jar&lt;/code&gt; shipped with JDKs (&amp;gt;=1.6) provide the magical
&lt;a href="http://www.docjar.com/docs/api/sun/tools/attach/HotSpotVirtualMachine.html"&gt;HotSpotVirtualMachine&lt;/a&gt;
class containing our saviour &lt;code&gt;remoteDataDump()&lt;/code&gt; method. First add the
following lines to your &lt;code&gt;pom.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="nt"&gt;&amp;lt;dependencyManagement&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;

        &lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;com.sun&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;tools&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${java.version}&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;system&lt;span class="nt"&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;systemPath&amp;gt;&lt;/span&gt;${tools.jar}&lt;span class="nt"&gt;&amp;lt;/systemPath&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;

    &lt;span class="nt"&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/dependencyManagement&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;profiles&amp;gt;&lt;/span&gt;

    &lt;span class="c"&gt;&amp;lt;!-- tools.jar path for GNU/Linux and Windows --&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;profile&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;id&amp;gt;&lt;/span&gt;default-tools.jar&lt;span class="nt"&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;activation&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;file&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;exists&amp;gt;&lt;/span&gt;${java.home}/../lib/tools.jar&lt;span class="nt"&gt;&amp;lt;/exists&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/file&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/activation&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;tools.jar&amp;gt;&lt;/span&gt;${java.home}/../lib/tools.jar&lt;span class="nt"&gt;&amp;lt;/tools.jar&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/profile&amp;gt;&lt;/span&gt;

    &lt;span class="c"&gt;&amp;lt;!-- tools.jar path for OSX --&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;profile&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;id&amp;gt;&lt;/span&gt;default-tools.jar-mac&lt;span class="nt"&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;activation&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;file&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;exists&amp;gt;&lt;/span&gt;${java.home}/../Classes/classes.jar&lt;span class="nt"&gt;&amp;lt;/exists&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/file&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/activation&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;tools.jar&amp;gt;&lt;/span&gt;${java.home}/../Classes/classes.jar&lt;span class="nt"&gt;&amp;lt;/tools.jar&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/profile&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;/profiles&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then the rest is a matter of accessing to &lt;code&gt;HotSpotVirtualMachine&lt;/code&gt; class:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.google.common.io.ByteStreams&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.sun.management.HotSpotDiagnosticMXBean&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.sun.tools.attach.AttachNotSupportedException&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.sun.tools.attach.VirtualMachine&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sun.tools.attach.HotSpotVirtualMachine&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.IOException&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.InputStream&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.lang.management.ManagementFactory&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;enum&lt;/span&gt; &lt;span class="n"&gt;HotSpotThreadDumps&lt;/span&gt; &lt;span class="o"&gt;{;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="nf"&gt;create&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;AttachNotSupportedException&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

        &lt;span class="c1"&gt;// Get the PID of the current JVM process.&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;selfName&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ManagementFactory&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getRuntimeMXBean&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="na"&gt;getName&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;selfPid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;selfName&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;substring&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;selfName&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;indexOf&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="sc"&gt;'@'&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;

        &lt;span class="c1"&gt;// Attach to the VM.&lt;/span&gt;
        &lt;span class="n"&gt;VirtualMachine&lt;/span&gt; &lt;span class="n"&gt;vm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;VirtualMachine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;attach&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;selfPid&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;HotSpotVirtualMachine&lt;/span&gt; &lt;span class="n"&gt;hotSpotVm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;HotSpotVirtualMachine&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="n"&gt;vm&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

        &lt;span class="c1"&gt;// Request a thread dump.&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InputStream&lt;/span&gt; &lt;span class="n"&gt;inputStream&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hotSpotVm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;remoteDataDump&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="kt"&gt;byte&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ByteStreams&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toByteArray&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputStream&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;String&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bytes&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You finished writing this code, you clicked on the Run button of the IDE, and
it worked like a charm. This get you so excited that you wanted to add this
functionality to your JEE service! Or better: Turn this into a JAR and pass it
to your client’s machine and watch them take their part in the joy of
thread-dump-oriented debugging! And this is what you get in return:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java.lang.NoClassDefFoundError: com/sun/tools/attach/AttachNotSupportedException
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which indicates that you did not pay attention my words: &lt;em&gt;&lt;code&gt;tools.jar&lt;/code&gt; is
shipped with JDKs.&lt;/em&gt; So neither your flashy JEE application server, nor your
client’s machine has a JDK, but a JRE. Rings a bell? Yes, you indeed can add
&lt;code&gt;tools.jar&lt;/code&gt; into the final WAR/JAR of your project:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="nt"&gt;&amp;lt;build&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;plugins&amp;gt;&lt;/span&gt;

        &lt;span class="c"&gt;&amp;lt;!-- copy tools.jar from JAVA_HOME --&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-dependency-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;id&amp;gt;&lt;/span&gt;copy-system-dependencies&lt;span class="nt"&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;prepare-package&lt;span class="nt"&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;copy-dependencies&lt;span class="nt"&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;outputDirectory&amp;gt;&lt;/span&gt;${project.build.directory}/${project.build.finalName}/WEB-INF/lib&lt;span class="nt"&gt;&amp;lt;/outputDirectory&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;includeScope&amp;gt;&lt;/span&gt;system&lt;span class="nt"&gt;&amp;lt;/includeScope&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;

    &lt;span class="nt"&gt;&amp;lt;/plugins&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/build&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that this approach incorporates a JDK-specific JAR into your application
and assumes that the application will run on a HotSpot VM. But unfortunately
this is the only way that I know of to produce a thread dump that works with
thread dump analysis software. If you don’t have such a need and just want a
crude JMX generated thread dump, check out
&lt;a href="https://java.net/projects/visualvm/sources/svn/content/branches/release134/visualvm/jmx/src/com/sun/tools/visualvm/jmx/impl/JmxSupport.java"&gt;JmxSupport.java&lt;/a&gt;
shipped with VisualVM.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2016-07-20://blog/post/2016/07/20/rxjava-backpressure/</id>
    <title type="html">Callback Blocking for Back-Pressure in RxJava</title>
    <published>2016-07-20T20:32:00Z</published>
    <updated>2016-07-20T20:32:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2016/07/20/rxjava-backpressure/"/>
    <content type="html">
&lt;p&gt;In a reactive application, you don’t necessarily have control over the
production and/or consumption rate of certain streams. This speed mismatch can
cause severe and hard to find bugs, which might be overlooked in development
environments while bringing in the entire system down in production.&lt;/p&gt;

&lt;h1 id="life-without-back-pressure"&gt;Life Without Back-Pressure&lt;/h1&gt;

&lt;p&gt;Consider the following example:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.google.common.base.Throwables&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;rx.Observable&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.atomic.AtomicInteger&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;enum&lt;/span&gt; &lt;span class="n"&gt;NoBackPressure&lt;/span&gt; &lt;span class="o"&gt;{;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

        &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;producePeriod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;consumePeriod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;AtomicInteger&lt;/span&gt; &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;AtomicInteger&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

        &lt;span class="c1"&gt;// Create a fast producer emitting an infinite number of items.&lt;/span&gt;
        &lt;span class="n"&gt;createStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;producePeriod&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nl"&gt;pendingTaskCount:&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;incrementAndGet&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
                &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;flatMap&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ignored&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;
                        &lt;span class="c1"&gt;// Create a slow consumer emitting just one item.&lt;/span&gt;
                        &lt;span class="n"&gt;createStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;consumePeriod&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nl"&gt;pendingTaskCount:&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;decrementAndGet&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
                &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;take&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
                &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toBlocking&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
                &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;last&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;format&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"pending task count: %d\n"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;

    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Observable&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;createStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;pausePeriodMillis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;boolean&lt;/span&gt; &lt;span class="n"&gt;infinite&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Supplier&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Observable&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;create&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subscriber&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;Thread&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                &lt;span class="nd"&gt;@Override&lt;/span&gt;
                &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                    &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                        &lt;span class="n"&gt;pause&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pausePeriodMillis&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
                        &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;next&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
                        &lt;span class="n"&gt;subscriber&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;onNext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
                    &lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;infinite&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="n"&gt;subscriber&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;isUnsubscribed&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
                &lt;span class="o"&gt;}&lt;/span&gt;
            &lt;span class="o"&gt;}.&lt;/span&gt;&lt;span class="na"&gt;start&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="o"&gt;});&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;pause&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;millis&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sleep&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;millis&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InterruptedException&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="n"&gt;Throwables&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;propagate&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What’s going on really here? The fast producer is an observable emitting an
item every 100ms and then incrementing the &lt;code&gt;pendingTaskCount&lt;/code&gt;. Subsequently,
the emitted item is &lt;code&gt;flatMap&lt;/code&gt;ed into another consumer observable emitting an
item every 300ms and then decrementing the &lt;code&gt;pendingTaskCount&lt;/code&gt;. That is, yet
another simple producer-consumer pipeline. Finally, we ask for the first 5
items emitted out of the pipeline. Can you guess the program output? Or let me
rephrase the question: Do you expect &lt;code&gt;pendingTaskCount&lt;/code&gt; to be non-zero?
Unfortunately, yes. It is 3 in this case. Let’s shed some more light into it:&lt;/p&gt;

&lt;p&gt;&lt;img src="prod-cons-pipeline.jpg" alt="Producer-Consumer Pipeline"&gt;&lt;/p&gt;

&lt;p&gt;As my spectular drawing skills depict above, during the completion of the
final 5th item, the producer generates 3 other items which later on get
processed by the slow consumer. So you have 3 extra threads lingering in the
background hogging both memory and processing resources. (Why 3? Because
&lt;code&gt;consumePeriod / producePeriod = 3&lt;/code&gt;.) While 3 seems like an innocent and hence
negligible magnitude, this speed unalignment can get a lot more worse once you
deploy the application to production. (Yes, it did in our case at work.) What
do I exactly mean by worse? &lt;em&gt;If we would set &lt;code&gt;consumePeriod&lt;/code&gt; to 10s, and
&lt;code&gt;producePeriod&lt;/code&gt; to 10ms, then there will be 1000 threads running in the
background at any particular point in time!&lt;/em&gt;&lt;/p&gt;

&lt;h1 id="rx-has-a-word-to-say"&gt;Rx Has a Word To Say!&lt;/h1&gt;

&lt;p&gt;In a nutshell, we need to come up with a way to regulate the production pace
in line with the consumption. We can either do this by an on-demand producer
(&lt;em&gt;reactive pull&lt;/em&gt;) or blocking the producer itself (&lt;em&gt;callstack blocking&lt;/em&gt;).
(Both in its &lt;a href="https://github.com/ReactiveX/RxJava/wiki/Backpressure"&gt;official
wiki&lt;/a&gt; and &lt;a href="http://stackoverflow.com/documentation/rx-java/2341/backpressure"&gt;Stack Overflow
Documentation&lt;/a&gt;,
RxJava has quite some juice on the subject.)&lt;/p&gt;

&lt;h2 id="discarding-the-over-production"&gt;Discarding the Over-Production&lt;/h2&gt;

&lt;p&gt;Three common methods provided out of the box by RxJava for dealing with
back-pressure are &lt;code&gt;onBackpressureBuffer&lt;/code&gt;, &lt;code&gt;onBackpressureDrop&lt;/code&gt;, and
&lt;code&gt;onBackpressureLatest&lt;/code&gt;. While they definitely do the trick, rather than
regulating the production speed, they just discard emitted items by the
producer under certain back-pressure circumstances. (I am keeping experimental
RxJava &amp;gt;1.0 feature &lt;code&gt;onBackpressureBlock&lt;/code&gt; out of this discussion due to its
ambiguous future and known track record of holding a potential to introduce
dead-locks.)&lt;/p&gt;

&lt;h2 id="reactive-pull"&gt;Reactive Pull&lt;/h2&gt;

&lt;p&gt;RxJava has one more bullet in the hand though:
&lt;a href="http://stackoverflow.com/documentation/rxjava/2341/backpressure"&gt;SyncOnSubscribe&lt;/a&gt;.
This almost orphan, totally undocumented prodigy, provides the necessary
harness to create &lt;em&gt;stateful&lt;/em&gt; and &lt;em&gt;on-demand&lt;/em&gt; producers:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="n"&gt;SyncOnSubscribe&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;InputStream&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;binaryReader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SyncOnSubscribe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;createStateful&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;

	&lt;span class="c1"&gt;// Create the initial state. (Invoked per subscriber.)&lt;/span&gt;
	&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;FileInputStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"data.bin"&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt;

	&lt;span class="c1"&gt;// Upon request, emit a new item and return the new state.&lt;/span&gt;
	&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputStream&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
		&lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
			&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="kt"&gt;byte&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inputStream&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;read&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
			&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;byte&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;onCompleted&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
			&lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;onNext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;byte&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
		&lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="n"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
			&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;onError&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
		&lt;span class="o"&gt;}&lt;/span&gt;
		&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;inputStream&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
	&lt;span class="o"&gt;},&lt;/span&gt;

	&lt;span class="c1"&gt;// Perform final clean-up using the state. (Invoked upon unsubscription.)&lt;/span&gt;
	&lt;span class="n"&gt;inputStream&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
		&lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="n"&gt;inputStream&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
		&lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="n"&gt;RxJavaHooks&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;onError&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
	&lt;span class="o"&gt;}&lt;/span&gt; 

&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;Observable&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;observableBinaryReader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Observable&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;create&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;binaryReader&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Awesome! We are done, right? Unfortunately not. In RxJava, unless you specify
otherwise, &lt;a href="http://reactivex.io/RxJava/javadoc/rx/Subscriber.html#request(long)"&gt;every consumer tries to pull &lt;code&gt;Long.MAX_VALUE&lt;/code&gt; items from the
observable it is subscribed
to&lt;/a&gt;. You
can change this beaviour by overriding this value:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="n"&gt;observableBinaryReader&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;subscribe&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Subscriber&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;onStart&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;    &lt;span class="c1"&gt;// Request 1 item on start up.&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;onNext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;compute&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;    &lt;span class="c1"&gt;// Request a new item after consuming one.&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;onError&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Throwable&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;printStackTrace&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;onCompleted&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Done!"&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;});&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In other words, the subscriber needs to be aware of the producer-consumer pace
mismatch and align them explicitly by limiting the number of requested items.
To the best of my knowledge, it is not possible to enforce the subscriber to
specify the number of requested items. You just need to hope that the next
programmer consuming your &lt;code&gt;Observable&amp;lt;T&amp;gt;&lt;/code&gt; will be able to figure out the
back-pressure problem and override the &lt;code&gt;request(Long.MAX_VALUE)&lt;/code&gt; behaviour.
(But you know that he won’t, right?)&lt;/p&gt;

&lt;p&gt;As a matter of fact, &lt;em&gt;reactive pull&lt;/em&gt; does not provide a solution for our
over-productive observable example, which just blindly emits items by ignoring
the consumer pace. We need a way to block the production according to the
consumption rate. And Rx literature has already got a term for this approach:
&lt;em&gt;Callstack Blocking&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id="callstack-blocking"&gt;Callstack Blocking&lt;/h2&gt;

&lt;p&gt;Shamelessly copying from the &lt;a href="https://github.com/ReactiveX/RxJava/wiki/Backpressure#callstack-blocking-as-a-flow-control-alternative-to-backpressure"&gt;RxJava wiki&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Another way of handling an over-productive &lt;code&gt;Observable&lt;/code&gt; is to block the
callstack (parking the thread that governs the over-productive
&lt;code&gt;Observable&lt;/code&gt;). This has the disadvantage of going against the &lt;em&gt;reactive&lt;/em&gt; and
non-blocking model of Rx. However this can be a viable option if the
problematic &lt;code&gt;Observable&lt;/code&gt; is on a thread that can be blocked safely.
Currently RxJava does not expose any operators to facilitate this.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But the good news is, you can implement this yourself. Let me walk-through you
how to do it.&lt;/p&gt;

&lt;h1 id="stack-your-own-back-pressure"&gt;Stack Your Own Back-Pressure&lt;/h1&gt;

&lt;p&gt;Let me introduce you to the poor man’s back-pressure queue.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;producePeriod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;consumePeriod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;AtomicInteger&lt;/span&gt; &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;AtomicInteger&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

    &lt;span class="c1"&gt;// The token queue for producer-consumer pipeline.&lt;/span&gt;
    &lt;span class="n"&gt;BlockingQueue&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ArrayBlockingQueue&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;(&lt;/span&gt;
            &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;                          &lt;span class="c1"&gt;// Number of tokens allowed.&lt;/span&gt;
            &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;                      &lt;span class="c1"&gt;// fair? (preserve the FIFO order?)&lt;/span&gt;
            &lt;span class="n"&gt;Collections&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;singleton&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;  &lt;span class="c1"&gt;// Initial tokens.&lt;/span&gt;

    &lt;span class="n"&gt;createStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;producePeriod&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;incrementAndGet&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="c1"&gt;// Try to acquire a token from the queue.&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;take&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InterruptedException&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="n"&gt;Throwables&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;propagate&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;})&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;flatMap&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;
                    &lt;span class="n"&gt;createStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;consumePeriod&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                        &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;decrementAndGet&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
                        &lt;span class="c1"&gt;// Push the token back into the queue.&lt;/span&gt;
                        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
                        &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InterruptedException&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="n"&gt;Throwables&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;propagate&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
                        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
                    &lt;span class="o"&gt;}))&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;take&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toBlocking&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;last&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

    &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;format&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"pending task count: %d\n"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we use a blocking queue to implement a token storage where producers
acquire from and consumers release to. This way we create a way to communicate
the back-pressure from consumers to the producer. Initially there is just a
single token. Producer acquires this token and emits an item. Note that the
upcoming producer call of the thread will block since there are no tokens left
in the queue. Next, consumer emits an item and releases the token back into
the queue. Now the blocked thread can proceed and emit a new item and so on.
By limiting the number of tokens initially available within the queue, we put
an upper limit on the number of concurrent consumptions. This version of our
producer-consumer pipeline reports that &lt;code&gt;pendingTaskCount&lt;/code&gt; is 1, which is
independent of the producer/consumer speed mismatch.&lt;/p&gt;

&lt;h1 id="back-pressure-for-the-masses"&gt;Back-Pressure for the Masses&lt;/h1&gt;

&lt;p&gt;Can we avoid having a global reference to the token storage and make it
explicit in the return type of the observable signature? Consider the
following two interfaces:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;interface&lt;/span&gt; &lt;span class="nc"&gt;BackPressuredFactory&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="nd"&gt;@Nonnull&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;BackPressured&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;acquire&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nd"&gt;@Nullable&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;instance&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;interface&lt;/span&gt; &lt;span class="nc"&gt;BackPressured&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="nd"&gt;@Nullable&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="nf"&gt;getValue&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;release&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A factory for creating instances of &lt;code&gt;BackPressured&amp;lt;T&amp;gt;&lt;/code&gt;, which encapsulates a
value associated with a certain token that is supposed to be released. Let’s
try to put them into use:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;producePeriod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;consumePeriod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;AtomicInteger&lt;/span&gt; &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;AtomicInteger&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

    &lt;span class="n"&gt;BackPressuredFactory&lt;/span&gt; &lt;span class="n"&gt;backPressuredFactory&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;BackPressuredFactoryImpl&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;
            &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;          &lt;span class="c1"&gt;// Number of concurrent tokens allowed.&lt;/span&gt;
            &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;      &lt;span class="c1"&gt;// Max. acquire/release timeout in milliseconds.&lt;/span&gt;

    &lt;span class="n"&gt;createStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;producePeriod&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;incrementAndGet&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="c1"&gt;// Wrap the next item with a BackPressured&amp;lt;T&amp;gt; instance.&lt;/span&gt;
        &lt;span class="n"&gt;BackPressured&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Void&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;next&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;backPressuredFactory&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;acquire&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;next&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;})&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;flatMap&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;backPressuredToken&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;
                    &lt;span class="n"&gt;createStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;consumePeriod&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                            &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;decrementAndGet&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
                            &lt;span class="c1"&gt;// Getting the value out of the back-pressured token.&lt;/span&gt;
                            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;backPressuredToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getValue&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
                        &lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;finally&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                            &lt;span class="c1"&gt;// Release the token.&lt;/span&gt;
                            &lt;span class="n"&gt;backPressuredToken&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;release&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
                        &lt;span class="o"&gt;}&lt;/span&gt;
                    &lt;span class="o"&gt;}))&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;take&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toBlocking&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;last&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

    &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;format&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"pending task count: %d\n"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pendingTaskCount&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In a nutshell, we encapsulate every item of type &lt;code&gt;T&lt;/code&gt; that producer emits into
a &lt;code&gt;BackPressured&amp;lt;T&amp;gt;&lt;/code&gt; instance. &lt;code&gt;BackPressuredFactory&lt;/code&gt; contains the token
storage. Given these requirements a sample implementation of these interfaces
can be given as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.slf4j.Logger&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.slf4j.LoggerFactory&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.List&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.ArrayBlockingQueue&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.BlockingQueue&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.TimeUnit&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.stream.Collectors&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.stream.IntStream&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;static&lt;/span&gt; &lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;google&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Preconditions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;checkArgument&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;BackPressuredFactoryImpl&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;BackPressuredFactory&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="n"&gt;Logger&lt;/span&gt; &lt;span class="n"&gt;LOGGER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LoggerFactory&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getLogger&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BackPressuredFactoryImpl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="n"&gt;BlockingQueue&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="nf"&gt;BackPressuredFactoryImpl&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;bufferSize&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;checkArgument&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bufferSize&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"bufferSize &amp;gt; 0, found: %d"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bufferSize&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;checkArgument&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timeoutMillis&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"timeoutMillis &amp;gt; 0, found: %d"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;initialTokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;IntStream&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;range&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bufferSize&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="na"&gt;boxed&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="na"&gt;collect&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Collectors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toList&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ArrayBlockingQueue&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class="n"&gt;bufferSize&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;initialTokens&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;timeoutMillis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;LOGGER&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;trace&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"initialized (bufferSize={}, timeoutMillis={})"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bufferSize&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Nonnull&lt;/span&gt;
    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;BackPressured&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;acquire&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nd"&gt;@Nullable&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;LOGGER&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;trace&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"acquiring (peekedToken={})"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;peek&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;Integer&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;poll&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TimeUnit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;MILLISECONDS&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;RuntimeException&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"token acquisition timeout"&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;BackPressuredImpl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InterruptedException&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;RuntimeException&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"token acquisition failure"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And here is &lt;code&gt;BackPressured&amp;lt;T&amp;gt;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.slf4j.Logger&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.slf4j.LoggerFactory&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.BlockingQueue&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.concurrent.TimeUnit&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;static&lt;/span&gt; &lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;google&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Preconditions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;checkArgument&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;static&lt;/span&gt; &lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;google&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;base&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Preconditions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;checkNotNull&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;BackPressuredImpl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="kd"&gt;implements&lt;/span&gt; &lt;span class="n"&gt;BackPressured&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="n"&gt;Logger&lt;/span&gt; &lt;span class="n"&gt;LOGGER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LoggerFactory&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getLogger&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BackPressuredImpl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="n"&gt;BlockingQueue&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;final&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="nf"&gt;BackPressuredImpl&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nd"&gt;@Nonnull&lt;/span&gt; &lt;span class="n"&gt;BlockingQueue&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;long&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nd"&gt;@Nullable&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;checkArgument&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timeoutMillis&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"timeoutMillis &amp;gt; 0, found: %d"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;checkNotNull&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"null tokens"&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;timeoutMillis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;LOGGER&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;trace&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"initialized (token={})"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Nullable&lt;/span&gt;
    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="nf"&gt;getValue&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

    &lt;span class="nd"&gt;@Override&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;release&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;LOGGER&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;trace&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"releasing (token={})"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;(!&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;offer&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TimeUnit&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;MILLISECONDS&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;format&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"token release timeout (timeoutMillis=%d, token=%d)"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
                &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;RuntimeException&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="o"&gt;}&lt;/span&gt;
            &lt;span class="n"&gt;LOGGER&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;trace&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"released (token={})"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
        &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InterruptedException&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;format&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"token release failure (timeoutMillis=%d, token=%d)"&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeoutMillis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
            &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;RuntimeException&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="o"&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Back-pressure is a significant aspect in every producer-consumer pipeline. It
can be easily overlooked and holds a potential to break the system depending
on the speed mismatch of the involved actors. In this post, I examined the
problem in a sample RxJava application and provided a solution leveraging
&lt;em&gt;callback blocking&lt;/em&gt; approach that can be employed in almost any domain where
the back-pressure needs to communicated. I hope you find it useful as well.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2016-03-02://blog/post/2016/03/02/optimize-dc/</id>
    <title type="html">Optimizing a Data Center Using Integer Programming</title>
    <published>2016-03-02T19:32:00Z</published>
    <updated>2016-03-02T19:32:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2016/03/02/optimize-dc/"/>
    <content type="html">
&lt;p&gt;&lt;a href="https://hashcode.withgoogle.com/2015/tasks/hashcode2015_qualification_task.pdf"&gt;Optimize a Data
Center&lt;/a&gt;
is a &lt;strong&gt;challenging&lt;/strong&gt; programming problem presented in the Qualification Round
of the &lt;a href="https://hashcode.withgoogle.com/past_editions.html"&gt;Hash Code 2015&lt;/a&gt;.
Among 230 teams, &lt;em&gt;What’s in a name?&lt;/em&gt; from &lt;a href="http://www.ens.fr/"&gt;École normale
supérieure&lt;/a&gt; ranked first in the qualification, but third
in the final round. By challenging, I mean it is not possible to come up with
a deterministic polynomial-time optimal answer. I am not in a position to
either provide a rigorous proof of its complexity or its reduction to a known
NP-hard problem. But in this blog post I will investigate the following
question: Can we provide an optimal solution using &lt;a href="https://en.wikipedia.org/wiki/Integer_programming"&gt;integer
programming&lt;/a&gt;? In practice,
that would allow us to come up with an optimal solution to small-sized
problems. Without further ado, let’s start with the problem definition.&lt;/p&gt;

&lt;h1 id="the-problem"&gt;The Problem&lt;/h1&gt;

&lt;p&gt;Here, I will present a brief summary of &lt;a href="https://hashcode.withgoogle.com/2015/tasks/hashcode2015_qualification_task.pdf"&gt;the actual
problem&lt;/a&gt;.
A data center is modeled as &lt;strong&gt;rows​&lt;/strong&gt; of &lt;strong&gt;slots&lt;/strong&gt; ​in which servers can be
placed. And some of the slots are known to be &lt;strong&gt;unavailable&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="rows.jpg" alt="Data center rows"&gt;&lt;/p&gt;

&lt;p&gt;Each &lt;strong&gt;server&lt;/strong&gt; is characterized by its &lt;strong&gt;size&lt;/strong&gt; and &lt;strong&gt;capacity​&lt;/strong&gt;. Size is
the number of consecutive slots occupied by the machine. Capacity is the total
amount of CPU resources of the machine (an integer value).&lt;/p&gt;

&lt;p&gt;&lt;img src="servers.jpg" alt="Data center servers"&gt;&lt;/p&gt;

&lt;p&gt;Servers in a data center are also logically divided into &lt;strong&gt;pools&lt;/strong&gt;. ​Each
server belongs to exactly one pool. The capacity of a pool is the sum of the
capacities of the available ​servers in that pool.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;guaranteed capacity&lt;/strong&gt; ​of a pool is the minimum capacity it will have
when at most one data center row goes down. Given a schema of a data center
and a list of available servers, the goal is to assign servers to slots within
the rows​ and to logical pools ​so that the lowest guaranteed capacity​ of all
pools is maximized.&lt;/p&gt;

&lt;p&gt;Consider the following data center schema and a list of available servers. For
simplicity, it is assumed that server capacities are equal to server sizes.&lt;/p&gt;

&lt;p&gt;&lt;img src="example-prob.jpg" alt="Example problem"&gt;&lt;/p&gt;

&lt;p&gt;Following layout is a solution to the above given problem. Here different
pools are denoted in distinct colors.&lt;/p&gt;

&lt;p&gt;&lt;img src="example-soln.jpg" alt="Example solution"&gt;&lt;/p&gt;

&lt;h1 id="preliminaries"&gt;Preliminaries&lt;/h1&gt;

&lt;p&gt;Before modeling the IP (Integer Program), I will start with stating the
problem input.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;R&lt;/script&gt; ​denotes the number of rows in the data center&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;S&lt;/script&gt; denotes the number of slots in each row of the data center&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;U \leq RS&lt;/script&gt; denotes the number of unavailable slots&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;P&lt;/script&gt; denotes the number of pools to be created&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;M \leq RS&lt;/script&gt; denotes the number of servers to be allocated&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;z_k&lt;/script&gt; and &lt;script type="math/tex"&gt;c_k&lt;/script&gt; denote &lt;script type="math/tex"&gt;k&lt;/script&gt;th server’s respectively size and capacity&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;r_i&lt;/script&gt; and &lt;script type="math/tex"&gt;s_i&lt;/script&gt; denote &lt;script type="math/tex"&gt;i&lt;/script&gt;th unavailable slot’s respectively row and
slot indices&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While modeling the formulation, I will need to provide constraints to avoid
placing servers to unavailable slots. Rather than doing that, &lt;a href="http://kaygun.tumblr.com/"&gt;Atabey
Kaygun&lt;/a&gt; hinted me to represent the data in
&lt;strong&gt;blocks&lt;/strong&gt;. That is, instead of &lt;script type="math/tex"&gt;U&lt;/script&gt;, &lt;script type="math/tex"&gt;r_i&lt;/script&gt;, and &lt;script type="math/tex"&gt;s_i&lt;/script&gt;, I will transform
this data into a single lookup table called &lt;script type="math/tex"&gt;z(i, j)&lt;/script&gt; that denotes the size
of the available slots at &lt;script type="math/tex"&gt;i&lt;/script&gt;th row and &lt;script type="math/tex"&gt;j&lt;/script&gt;th block. For instance,
consider the following layout:&lt;/p&gt;

&lt;p&gt;&lt;img src="blocks.jpg" alt="Example blocks"&gt;&lt;/p&gt;

&lt;p&gt;Here blocks will look as follows:&lt;/p&gt;

&lt;script type="math/tex; mode=display"&gt;% &lt;![CDATA[
\begin{align}
[z(0, 0)] &amp;= [10] \\
[z(1, 0), z(1, 1)] &amp;= [5,3] \\
[z(2, 0), z(2, 1), z(2, 2)] &amp;= [3, 4, 1] \\
[z(3, 0)] &amp;= [6]
\end{align} %]]&gt;&lt;/script&gt;

&lt;h1 id="the-integer-programming-model"&gt;The Integer Programming Model&lt;/h1&gt;

&lt;p&gt;For simplicity, I will adopt the following index notation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;i&lt;/script&gt; denotes row indices (&lt;script type="math/tex"&gt;0 \leq i \leq R&lt;/script&gt;)&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;j&lt;/script&gt; denotes block (not slot!) indices (varies per row)&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;k&lt;/script&gt; denotes server indices (&lt;script type="math/tex"&gt;0 \leq k \leq M&lt;/script&gt;)&lt;/li&gt;
  &lt;li&gt;
&lt;script type="math/tex"&gt;\ell&lt;/script&gt; denotes pool indices (&lt;script type="math/tex"&gt;0 \leq \ell \leq P&lt;/script&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given that &lt;script type="math/tex"&gt;z(i, j)&lt;/script&gt; denotes the available blocks, the IP model can be
defined as follows:&lt;/p&gt;

&lt;script type="math/tex; mode=display"&gt;% &lt;![CDATA[
\begin{align}

\text{maximize}
&amp; \quad
\min_\ell g(\ell)
\quad \text{(minimum of pool guaranteed capacities)} \\

\text{subject to}

&amp; \quad
\sum_\ell a(i, j, k, \ell) \leq 1, \, \forall k
\quad \text{(a server can be assigned to at most 1 pool and block)} \\

&amp; \quad
\sum_{k,\ell} z_k \, a(i, j, k, \ell) \leq z(i, j), \, \forall i, j
\quad \text{(total size of servers within a block cannot exceed block's size)} \\

\text{where}
&amp; \quad
a(i, j, k, \ell) =
\begin{cases}
    1       &amp; \quad \text{if } k \text{th server is assigned to } (i, j) \text{th block and } \ell \text{th pool} \\
    0  &amp; \quad \text{otherwise} \\
  \end{cases} \\

&amp; \quad
g(\ell) = \min_i g(\ell, i)
\quad \text{(guaranteed capacity of } \ell \text{th pool)} \\

&amp; \quad
g(\ell, i) = \sum_{i', j, k} c_k \, a(i', j, k, \ell) - \sum_{j, k} c_k \, a(i, j, k, \ell)
\quad \text{(guaranteed capacity of } \ell \text{th pool for } i \text{th row)} \\

\end{align} %]]&gt;&lt;/script&gt;

&lt;h1 id="avoiding-minimax-constraint"&gt;Avoiding Minimax Constraint&lt;/h1&gt;

&lt;p&gt;The presented IP model contains a minimax objective, which to the best of my
knowledge is not tractable by popular linear programming optimizers, such as
&lt;a href="http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/"&gt;CPLEX&lt;/a&gt;
or &lt;a href="http://lpsolve.sourceforge.net/"&gt;lpsolve&lt;/a&gt;. But I have a trick in my pocket
to tackle that. Let’s assume that we know the optimal objective, say &lt;script type="math/tex"&gt;g^*&lt;/script&gt;.
Then we can model the entire IP as follows:&lt;/p&gt;

&lt;script type="math/tex; mode=display"&gt;% &lt;![CDATA[
\begin{align}

\text{maximize}
&amp; \quad
1
\quad \text{(a dummy objective)} \\

&amp; \quad
\sum_\ell a(i, j, k, \ell) \leq 1, \, \forall k \\

&amp; \quad
\sum_{k,\ell} z_k \, a(i, j, k, \ell) \leq z(i, j), \, \forall i, j \\

&amp; \quad
g(\ell, i) \geq g^*, \, \forall \ell, i
\quad \text{(guaranteed capacity must be greater than or equal to } g^* \text{)} \\

\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;What this model states is this: I am not interested in the optimization
objective, return me the first found feasible solution. That is, the optimizer
will return us the first &lt;script type="math/tex"&gt;a(i, j, k, \ell)&lt;/script&gt; variable set the moment it finds
a feasible solution satisfying &lt;script type="math/tex"&gt;g(\ell, i) \geq g^*, \, \forall \ell, i&lt;/script&gt;
constraints.&lt;/p&gt;

&lt;p&gt;Now things are getting interesting. If we can find bounds to &lt;script type="math/tex"&gt;g^*&lt;/script&gt;, than we
can use these bounds to bisect the optimal &lt;script type="math/tex"&gt;g^*&lt;/script&gt;! For the lower bound, we
know that &lt;script type="math/tex"&gt;g_i = 0 \leq g^*&lt;/script&gt;. The upper bound is a little bit tricky, but we
can come up with a quite loose bound: &lt;script type="math/tex"&gt;g_f = \frac{1}{P} \sum_k c_k \gg
g^*&lt;/script&gt;. (I will not go into details of how to come up with a stricter upper
bound.) So by picking &lt;script type="math/tex"&gt;g^* \in (g_i, g_f)&lt;/script&gt; we can bisect &lt;strong&gt;the optimal
guaranteed capacity&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id="the-solver"&gt;The Solver&lt;/h1&gt;

&lt;p&gt;For testing purposes, I wrote a simple &lt;a href="https://gist.github.com/vy/9689cb122a84be22d454"&gt;Python
script&lt;/a&gt; that reads an input
problem file and calls CPLEX iteratively. A sample output of the script is as
follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./dc.py ./cplex.sh prob/dc-min.in soln/dc-min 0
2016-03-03 08:35:25 DEBUG    reading setup: prob/dc-min.in
2016-03-03 08:35:25 DEBUG    R=2, S=5, U=1, P=2, M=5
2016-03-03 08:35:25 INFO     solving for 0 &amp;lt;= g=8 &amp;lt; 16
2016-03-03 08:35:25 DEBUG    writing problem: soln/dc-min-8.lp
2016-03-03 08:35:25 DEBUG    running solver
2016-03-03 08:35:25 DEBUG    writing cplex output: soln/dc-min-8.out
2016-03-03 08:35:25 DEBUG    no solution
2016-03-03 08:35:25 DEBUG    stepping back
2016-03-03 08:35:25 INFO     solving for 0 &amp;lt;= g=4 &amp;lt; 8
2016-03-03 08:35:25 DEBUG    writing problem: soln/dc-min-4.lp
2016-03-03 08:35:25 DEBUG    running solver
2016-03-03 08:35:25 DEBUG    writing cplex output: soln/dc-min-4.out
2016-03-03 08:35:25 DEBUG    solution score: 5
2016-03-03 08:35:25 DEBUG    writing solution: soln/dc-min-4.soln
2016-03-03 08:35:25 DEBUG    stepping forward
2016-03-03 08:35:25 INFO     solving for 5 &amp;lt;= g=6 &amp;lt; 8
2016-03-03 08:35:25 DEBUG    writing problem: soln/dc-min-6.lp
2016-03-03 08:35:25 DEBUG    running solver
2016-03-03 08:35:25 DEBUG    writing cplex output: soln/dc-min-6.out
2016-03-03 08:35:25 DEBUG    no solution
2016-03-03 08:35:25 DEBUG    stepping back
2016-03-03 08:35:25 INFO     solving for 5 &amp;lt;= g=5 &amp;lt; 6
2016-03-03 08:35:25 DEBUG    writing problem: soln/dc-min-5.lp
2016-03-03 08:35:25 DEBUG    running solver
2016-03-03 08:35:25 DEBUG    writing cplex output: soln/dc-min-5.out
2016-03-03 08:35:25 DEBUG    solution score: 5
2016-03-03 08:35:25 DEBUG    writing solution: soln/dc-min-5.soln
2016-03-03 08:35:25 DEBUG    stepping forward
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It also outputs intermediate IP formulation files, CPLEX output, and solution
file. The format of the problem and solution files are detailed in &lt;a href="https://hashcode.withgoogle.com/2015/tasks/hashcode2015_qualification_task.pdf"&gt;the
official problem
description&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:vlkan.com,2015-11-27://blog/post/2015/11/27/maven-protobuf/</id>
    <title type="html">Compiling Protocol Buffers Sources in Maven</title>
    <published>2015-11-27T08:49:00Z</published>
    <updated>2015-11-27T08:49:00Z</updated>
    <link rel="alternate" href="https://vlkan.com//blog/post/2015/11/27/maven-protobuf/"/>
    <content type="html">
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; – This post explains how to compile Protocol Buffers schemas into
Java sources in Maven. Over the course of time, there appeared plugins like
&lt;a href="https://github.com/os72/protoc-jar-maven-plugin"&gt;protoc-jar-maven-plugin&lt;/a&gt;.
Nevertheless, the steps below still present a value to understand the
necessary plumbing and some best practices (e.g., shading) that are not
covered by the plugins.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Java build systems have always been a second class citizen for &lt;a href="https://developers.google.com/protocol-buffers"&gt;Protocol
Buffers&lt;/a&gt;. As is the case for
many other Java serialization frameworks (e.g., &lt;a href="https://capnproto.org/"&gt;Cap’n
Proto&lt;/a&gt;,
&lt;a href="http://google.github.io/flatbuffers/"&gt;FlatBuffers&lt;/a&gt;), Protocol Buffers does
not provide a native Java compiler which you can inject into Maven
dependencies and invoke a plugin to compile &lt;code&gt;.proto&lt;/code&gt; files into &lt;code&gt;.java&lt;/code&gt;
sources. Hence, programmers needed to have &lt;code&gt;protoc&lt;/code&gt; (Proto Buffers Compiler)
binary on their development machine and call this platform-dependent binary
during Maven build. This totally violates the environment independent build of
a project. Fortunately, Google releases platform-specific &lt;code&gt;protoc&lt;/code&gt; binaries in
the form of Maven artifacts.&lt;/p&gt;

&lt;p&gt;&lt;img src="protoc-artifacts.png" alt="Maven Artifacts for Proto Buffers Compiler Binary"&gt;&lt;/p&gt;

&lt;p&gt;We can add these artifacts as a compile-time dependency to our Maven project
and invoke the platform-dependent binary to compile &lt;code&gt;.proto&lt;/code&gt; sources.&lt;/p&gt;

&lt;h1 id="preliminaries"&gt;Preliminaries&lt;/h1&gt;

&lt;p&gt;Let’s start with defining certain properties for library versions and
input/output directories for the Protocol Buffers compiler.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="nt"&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;

    &lt;span class="c"&gt;&amp;lt;!-- protobuf paths --&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;protobuf.input.directory&amp;gt;&lt;/span&gt;${project.basedir}/src/main/proto&lt;span class="nt"&gt;&amp;lt;/protobuf.input.directory&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;protobuf.output.directory&amp;gt;&lt;/span&gt;${project.build.directory}/generated-sources&lt;span class="nt"&gt;&amp;lt;/protobuf.output.directory&amp;gt;&lt;/span&gt;

    &lt;span class="c"&gt;&amp;lt;!-- library versions --&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;build-helper-maven-plugin.version&amp;gt;&lt;/span&gt;1.9.1&lt;span class="nt"&gt;&amp;lt;/build-helper-maven-plugin.version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;maven-antrun-plugin.version&amp;gt;&lt;/span&gt;1.8&lt;span class="nt"&gt;&amp;lt;/maven-antrun-plugin.version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;maven-dependency-plugin.version&amp;gt;&lt;/span&gt;2.10&lt;span class="nt"&gt;&amp;lt;/maven-dependency-plugin.version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;maven-shade-plugin.version&amp;gt;&lt;/span&gt;2.4.2&lt;span class="nt"&gt;&amp;lt;/maven-shade-plugin.version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;os-maven-plugin.version&amp;gt;&lt;/span&gt;1.4.1.Final&lt;span class="nt"&gt;&amp;lt;/os-maven-plugin.version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;protobuf.version&amp;gt;&lt;/span&gt;3.0.0-beta-1&lt;span class="nt"&gt;&amp;lt;/protobuf.version&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id="protocol-buffers-java-api"&gt;Protocol Buffers Java API&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;protoc&lt;/code&gt; compiles &lt;code&gt;.proto&lt;/code&gt; files into &lt;code&gt;.java&lt;/code&gt; files such that the generated
sources rely on certain common classes. These classes are provided by
&lt;code&gt;protobuf-java&lt;/code&gt; artifact:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="nt"&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;com.google.protobuf&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;protobuf-java&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${protobuf.version}&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id="detecting-operating-system"&gt;Detecting Operating System&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;protoc&lt;/code&gt; Maven artifact is provided in various platform-specific
&lt;em&gt;classifications&lt;/em&gt;: &lt;code&gt;linux-x86_32&lt;/code&gt;, &lt;code&gt;linux-x86_64&lt;/code&gt;, &lt;code&gt;osx-x86_32&lt;/code&gt;, &lt;code&gt;osx-x86_64&lt;/code&gt;,
&lt;code&gt;windows-x86_32&lt;/code&gt;, &lt;code&gt;windows-x86_64&lt;/code&gt;. In order to pick the right artifact, we
will employ &lt;code&gt;os.detected.classifier&lt;/code&gt; property exposed by &lt;code&gt;os-maven-plugin&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="nt"&gt;&amp;lt;build&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;extensions&amp;gt;&lt;/span&gt;
        &lt;span class="c"&gt;&amp;lt;!-- provides os.detected.classifier (i.e. linux-x86_64, osx-x86_64) property --&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;extension&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;kr.motd.maven&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;os-maven-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${os-maven-plugin.version}&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/extension&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/extensions&amp;gt;&lt;/span&gt;

    &lt;span class="c"&gt;&amp;lt;!-- ... --&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/build&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id="downloading-platform-specific-protocol-buffers-compiler"&gt;Downloading Platform-Specific Protocol Buffers Compiler&lt;/h1&gt;

&lt;p&gt;We will use &lt;code&gt;maven-dependency-plugin&lt;/code&gt; to download the platform-specific
&lt;code&gt;protoc&lt;/code&gt; binary suitable for the current build platform and copy it into
&lt;code&gt;project.build.directory&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="c"&gt;&amp;lt;!-- copy protoc binary into build directory --&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-dependency-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${maven-dependency-plugin.version}&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;id&amp;gt;&lt;/span&gt;copy-protoc&lt;span class="nt"&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;generate-sources&lt;span class="nt"&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;copy&lt;span class="nt"&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;artifactItems&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;artifactItem&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;com.google.protobuf&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;protoc&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${protobuf.version}&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;classifier&amp;gt;&lt;/span&gt;${os.detected.classifier}&lt;span class="nt"&gt;&amp;lt;/classifier&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;type&amp;gt;&lt;/span&gt;exe&lt;span class="nt"&gt;&amp;lt;/type&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;overWrite&amp;gt;&lt;/span&gt;true&lt;span class="nt"&gt;&amp;lt;/overWrite&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;outputDirectory&amp;gt;&lt;/span&gt;${project.build.directory}&lt;span class="nt"&gt;&amp;lt;/outputDirectory&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/artifactItem&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/artifactItems&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note how we employed &lt;code&gt;os.detected.classifier&lt;/code&gt; variable provided by
&lt;code&gt;os-maven-plugin&lt;/code&gt; to inject the platform-specific binary dependency.&lt;/p&gt;

&lt;h1 id="generating-protocol-buffers-java-sources"&gt;Generating Protocol Buffers Java Sources&lt;/h1&gt;

&lt;p&gt;Now we have our &lt;code&gt;protoc&lt;/code&gt; binary in &lt;code&gt;project.build.directory&lt;/code&gt;. We can use
&lt;code&gt;maven-antrun-plugin&lt;/code&gt; plugin to execute &lt;code&gt;protoc&lt;/code&gt; for compiling &lt;code&gt;.proto&lt;/code&gt; files
into &lt;code&gt;.java&lt;/code&gt; sources.&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="c"&gt;&amp;lt;!-- compile proto buffer files using copied protoc binary --&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-antrun-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${maven-antrun-plugin.version}&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;id&amp;gt;&lt;/span&gt;exec-protoc&lt;span class="nt"&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;generate-sources&lt;span class="nt"&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;target&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"protoc.filename"&lt;/span&gt; &lt;span class="na"&gt;value=&lt;/span&gt;&lt;span class="s"&gt;"protoc-${protobuf.version}-${os.detected.classifier}.exe"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"protoc.filepath"&lt;/span&gt; &lt;span class="na"&gt;value=&lt;/span&gt;&lt;span class="s"&gt;"${project.build.directory}/${protoc.filename}"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;chmod&lt;/span&gt; &lt;span class="na"&gt;file=&lt;/span&gt;&lt;span class="s"&gt;"${protoc.filepath}"&lt;/span&gt; &lt;span class="na"&gt;perm=&lt;/span&gt;&lt;span class="s"&gt;"ugo+rx"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;mkdir&lt;/span&gt; &lt;span class="na"&gt;dir=&lt;/span&gt;&lt;span class="s"&gt;"${protobuf.output.directory}"&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;path&lt;/span&gt; &lt;span class="na"&gt;id=&lt;/span&gt;&lt;span class="s"&gt;"protobuf.input.filepaths.path"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;fileset&lt;/span&gt; &lt;span class="na"&gt;dir=&lt;/span&gt;&lt;span class="s"&gt;"${protobuf.input.directory}"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                            &lt;span class="nt"&gt;&amp;lt;include&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;"**/*.proto"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;/fileset&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/path&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;pathconvert&lt;/span&gt; &lt;span class="na"&gt;pathsep=&lt;/span&gt;&lt;span class="s"&gt;" "&lt;/span&gt; &lt;span class="na"&gt;property=&lt;/span&gt;&lt;span class="s"&gt;"protobuf.input.filepaths"&lt;/span&gt; &lt;span class="na"&gt;refid=&lt;/span&gt;&lt;span class="s"&gt;"protobuf.input.filepaths.path"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;exec&lt;/span&gt; &lt;span class="na"&gt;executable=&lt;/span&gt;&lt;span class="s"&gt;"${protoc.filepath}"&lt;/span&gt; &lt;span class="na"&gt;failonerror=&lt;/span&gt;&lt;span class="s"&gt;"true"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;arg&lt;/span&gt; &lt;span class="na"&gt;value=&lt;/span&gt;&lt;span class="s"&gt;"-I"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;arg&lt;/span&gt; &lt;span class="na"&gt;value=&lt;/span&gt;&lt;span class="s"&gt;"${protobuf.input.directory}"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;arg&lt;/span&gt; &lt;span class="na"&gt;value=&lt;/span&gt;&lt;span class="s"&gt;"--java_out"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;arg&lt;/span&gt; &lt;span class="na"&gt;value=&lt;/span&gt;&lt;span class="s"&gt;"${protobuf.output.directory}"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;arg&lt;/span&gt; &lt;span class="na"&gt;line=&lt;/span&gt;&lt;span class="s"&gt;"${protobuf.input.filepaths}"&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/exec&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/target&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;run&lt;span class="nt"&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id="adding-generated-sources-into-the-package"&gt;Adding Generated Sources into the Package&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;protoc&lt;/code&gt; compiler placed the generated Java sources into
&lt;code&gt;protobuf.output.directory&lt;/code&gt;. We need to add the sources in this directory to
the package:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="c"&gt;&amp;lt;!-- add generated proto buffer classes into the package --&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.codehaus.mojo&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;build-helper-maven-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${build-helper-maven-plugin.version}&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;id&amp;gt;&lt;/span&gt;add-classes&lt;span class="nt"&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;generate-sources&lt;span class="nt"&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;add-source&lt;span class="nt"&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;sources&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;source&amp;gt;&lt;/span&gt;${protobuf.output.directory}&lt;span class="nt"&gt;&amp;lt;/source&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/sources&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id="shading-protocol-buffers-package"&gt;Shading Protocol Buffers Package&lt;/h1&gt;

&lt;p&gt;Say you are done with your project, which includes &lt;code&gt;protobuf-java&lt;/code&gt; version
3.0.0-beta-1 as a dependency. What if there is another package that is
included as a direct or transitive Maven dependency and injects
&lt;code&gt;protobuf-java&lt;/code&gt; version 2.5.0? Then you are doomed; you will get a package
version conflict. In order to avoid this problem, you can leverage
&lt;code&gt;maven-shade-plugin&lt;/code&gt; to &lt;em&gt;relocate&lt;/em&gt; &lt;code&gt;com.google.protobuf&lt;/code&gt; package contents to a
private package within your project:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span class="c"&gt;&amp;lt;!--  shade protobuf to avoid version conflicts --&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class="nt"&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-shade-plugin&lt;span class="nt"&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${maven-shade-plugin.version}&lt;span class="nt"&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;package&lt;span class="nt"&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;shade&lt;span class="nt"&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;relocations&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;relocation&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;pattern&amp;gt;&lt;/span&gt;com.google.protobuf&lt;span class="nt"&gt;&amp;lt;/pattern&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;shadedPattern&amp;gt;&lt;/span&gt;${project.groupId}.${project.artifactId}.shaded.protobuf&lt;span class="nt"&gt;&amp;lt;/shadedPattern&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/relocation&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/relocations&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will relocate the contents of &lt;code&gt;com.google.protobuf&lt;/code&gt; package to
&lt;code&gt;${project.groupId}.${project.artifactId}.shaded.protobuf&lt;/code&gt; and make the
classes accessible under this namespace. That is, instead of using&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;com.google.protobuf.*&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in your project, you should use the new relocated package name:&lt;/p&gt;

&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;groupId.artifactId.shaded.protobuf.*&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Note that you need to replace &lt;code&gt;groupId&lt;/code&gt; and &lt;code&gt;artifactId&lt;/code&gt; literals in the Java
code.)&lt;/p&gt;

&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;In this post, I tried to summarize the necessary set of steps to compile
Protocol Buffers schema into Java classes using plain Maven magic. This is
important to get a platform-independent build for a project.&lt;/p&gt;

&lt;p&gt;The absence of a proper Maven plugin to handle all these steps for us causes
quite a bit of &lt;code&gt;pom.xml&lt;/code&gt; pollution. Nevertheless, (de)serializers for the
messaging medium are generally distributed in a separate artifact, hence this
will probably end up being the entire content of your &lt;code&gt;pom.xml&lt;/code&gt;.&lt;/p&gt;
</content>
  </entry>
</feed>

